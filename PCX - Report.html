<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Plagiarism Checking Result for your Document</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link href="http://plagiarismcheckerx.com/css/jatt.css" rel="stylesheet">
<div id="div_wait" style="display: none; font-size: 14px;">Please wait, Your report is being rendered.</div>
<script type="text/javascript" src="http://plagiarismcheckerx.com/js/jquery-1.4.2.min.js"></script>
<script src="http://plagiarismcheckerx.com/js/jquery.jatt.js"></script>
</head>
<body onload="document.getElementById('div_wait').style.display='none';"> <!--oncontextmenu="return false"-->
<div id="wrap">
<div class="header_report">
<div class="content_box">
<h1 style="padding-left: 40px;font-size:28px;">Plagiarism Checker X Originality Report</h1>
<!--Trial_Info
<p style="padding-left: 70px">This report is generated by the Unregistered PlagiarismCheckerX <b>Demo version!</b></p>
Trial_Info-->

<!--Trial_Info
<p style="padding-left:120px;padding-top: 10px;"><a href="http://plagiarismcheckerx.com" target="_blank">Register the software</a> and get the complete functionality!</p>
Trial_Info-->

<table border="0">
<tr>
<td style="padding-left: 70px; padding-top: 15px;"><a href="http://plagiarismcheckerx.com" target="_blank"><img width="128px" height="93px" src="http://plagiarismcheckerx.com/images/PlagiarismCheckerX-Icon.png" / ></a></td>
<td align="middle"><h4> Plagiarism Quantity: 14% Duplicate</h4></td>
</tr>	
</table>

<div class="primary">
<div id="content">
<div class="textarea-wrapper">
<table width="100%" border="1" id="newspaper-c">
<tr>
<td width="90px"> Date </td>
<td width="650px"> Saturday, December 21, 2019</td>
</tr>
<tr>
<td> Words </td>
<td> 2108 Plagiarized Words / Total 14654 Words</td>
</tr>

<tr>
<td> Sources </td>
<td> More than 175 Sources Identified.</td>
</tr>

<tr>
<td> Remarks </td>
<td> Low Plagiarism Detected - Your Document needs Optional Improvement. </td>
</tr>
</table>
<div class="txt_check_plag">
<p>
<!--Header_End-->
<input type="hidden" id="version"  value="1.0">

<span id="n0" class="tooltip null_selection" title=" "> R E A L T I M E B A L L T R A C K E R A N D G O A L K E E P E R C a p s t o n e P r o j e c t R e p o r t E n d - S e m e s t e r E v a l u a t i o n Submitted by:</span><span id="n1" class="tooltip null_selection" title=" "> (101610091)Taranjeet Singh (101610093)Vaibhav Sood (101603364)Utkarsh Chugh (101611057)Tushar Mahajan BE Final Year, COE CPG No: 27 U n d e r t h e M e n t o r s</span><span id="n2" class="tooltip red_selection" title=" "> h i p o f D r .</span><span id="n3" class="tooltip null_selection" title=" "> R a m a n G o y a l A s s i s t a n t P r o f e s s o r C o m p u t e r S c i e n c e a n d E n g i n e e r i n g D e p a r t m e n t T I E T , P a t i a l a D e</span><span id="n4" class="tooltip null_selection" title=" "> c e m b e r 2 0 1 9 A B S T R A C T In this report we will discuss our project of autonomous goalkeeper in detail.<br /><br /></span><span id="n5" class="tooltip null_selection" title=" "> All the diagrams and every little detail needed to understand the concept of autonomous moving target tracker and interceptor.</span><span id="n6" class="tooltip null_selection" title=" "> Our basic approach to dealing with this problem would be to use OpenCV to track the ball and use a bot that would stop the ball in turn.</span><span id="n7" class="tooltip null_selection" title=" "> The blocking commands will be transferred from the PC to the bot via a zigbee.</span><span id="n8" class="tooltip null_selection" title=" "> The Python script we developed was able to detect the presence of a colored ball, followed by the track and the position of the ball as it moved around the screen.<br /><br /></span><span id="n9" class="tooltip null_selection" title=" "> As it shows, our system was fully robust and capable of tracing the ball, even if it was partially stopped when viewed by hand.</span><span id="n10" class="tooltip null_selection" title=" "> The script was also able to operate at extremely high frame rates (30 fps), concluding that color-based tracing methods are very suitable for real-time detection</span><span id="n11" class="tooltip null_selection" title=" "> and tracking. Ball-tracking is classified as follows: - Dense optical flow: These algorithms help us to estimate the vector of every pixel in a video frame.</span><span id="n12" class="tooltip null_selection" title=" "> Sparse optical flow: These algorithms, such as the Kanade Lucas Tomashi (KLT) tracker, detect the location of some characteristic points in a digital image.<br /><br /></span><span id="n13" class="tooltip red_selection" title=" "> Kalman filtering: It is a popular signal processing algorithm that is used to predict the location of a moving object based on the final motion information.</span><span id="n14" class="tooltip null_selection" title=" "> One of the most commonly used applications of this algorithm is missile guidance, as described here, "The on-board computer that directed the landing of the Apollo</span><span id="n15" class="tooltip red_selection" title=" "> 11 lunar module on the Earth's moon was a Kalman filter". . Meanshift and camshift: These are algos for detecting the maxima of a density function.</span><span id="n16" class="tooltip null_selection" title=" "> They are also used for tracking.<br /><br /></span><span id="n17" class="tooltip null_selection" title=" "> Single or One Object Trackers: In this category of trackers, the first frame is marked using a rectangle to indicate the position of the object we wanted to track.</span><span id="n15" class="tooltip red_selection" title=" "> The object is then tracked into the following frames using a tracking algo. In most real-life applications, these trackers are used with the help of an object detector.</span><span id="n19" class="tooltip null_selection" title=" "> Finding Multiple Object Track Algorithms: In cases when we have a fast object detector, it makes sense to detect multiple objects in each frame and then run a track</span><span id="n20" class="tooltip null_selection" title=" "> finding algorithm that identifies rectangles in one frame. is.<br /><br /></span><span id="n21" class="tooltip null_selection" title=" "> ii D E C L A R A T I O N We hereby declare that the design principles and working prototype model of the project entitled “Real Time Ball Tracker and Goalkeeper”</span><span id="n22" class="tooltip null_selection" title=" "> is an authentic record of our own work carried out in the Computer Science and Engineering Department, TIET, Patiala, under the guidance of Dr.Raman</span><span id="n23" class="tooltip null_selection" title=" "> Goyal ? during 6 ? t h ? semester (2019). Date: 17 ? t h ? .Dec.2019 Roll No.</span><span id="n24" class="tooltip null_selection" title=" "> Name Signature 101610091 Taranjeet Singh 101610093 Vaibhav Sood 101603364 Utkarsh Chugh 101611057 Tushar Mahajan Counter Signed By: Faculty Mentor: Dr.<br /><br /></span><span id="n25" class="tooltip null_selection" title=" "> ? Raman Goyal Assistant Professor Computer Science & Engineering Department, TIET, Patiala i i i A C K N O W L E D G E M E N T We would like to express our thanks</span><span id="n26" class="tooltip null_selection" title=" "> to our mentor Dr. Raman Goyal . He has been of great help in our venture, and an indispensable resource of technical knowledge.</span><span id="n27" class="tooltip null_selection" title=" "> He is truly an amazing mentor to have. We are also thankful to Dr.</span><span id="n28" class="tooltip red_selection" title=" "> Maninder Singh, Head of Computer Science and Engineering Department(HOD), the entire faculty and staff of Computer Science and Engineering Department, and also our</span><span id="n29" class="tooltip null_selection" title=" "> colleagues who devoted their valuable time and helped us in all possible ways towards successful completion of this project.<br /><br /></span><span id="n30" class="tooltip red_selection" title=" "> We thank all those who have helped either directly or indirectly towards completing this project.</span><span id="n31" class="tooltip null_selection" title=" "> Lastly, we would very much like to thank our families for their unyielding love and encouragement.</span><span id="n32" class="tooltip null_selection" title=" "> They always want the best for us and we deeply admire their determination and sacrifice. Date:17 ? t h ? .Dec.2019 Roll No.</span><span id="n33" class="tooltip null_selection" title=" "> Name Signature 101610091 Taranjeet Singh 101610093 Vaibhav Sood 101603364 Utkarsh Chugh 101611057 Tushar Mahajan i v T A B L E O F C O N T E N T S ABSTRACT……………………………………………………………………………………...ii<br /><br /></span><span id="n34" class="tooltip null_selection" title=" "> DECLARATION………………………………………………………………………………..iii ACKNOWLEDGEMENT……………………………………………………………………...iv LIST OF TABLES……………………………………………………………………………..viii LIST OF FIGURES……………………………………………………………………………..ix</span><span id="n35" class="tooltip null_selection" title=" "> LIST OF ABBREVIATIONS………………………………………………………………......xi CHAPTER 1- INTRODUCTION 1.1 Project Overview ………………………....…………………………………………..1 1.1.1 Technical terminology …………………...…………………………………….1</span><span id="n36" class="tooltip null_selection" title=" "> 1.1.2 Problem statement ………………………………………...…………….………1 1.1.3 Goal ………………………………………………………………..….………..2 1.1.4 Solution ……………………………………………………………….…..…….2 1.2</span><span id="n37" class="tooltip null_selection" title=" "> Need Analysis ……………………………………………………………….…....…..3 1.3 Research Gaps ……………………………………………………………….…….....3 1.4 Problem Definition and Scope ……………………………………………....………4 1.5<br /><br /></span><span id="n38" class="tooltip null_selection" title=" "> Assumptions and Constraints …………………………………………….…..………5 1.6 Approved Objectives …………………………………………………….…..………5 1.7 Methodology Used ……………………………………………………….….………6 1.8</span><span id="n39" class="tooltip null_selection" title=" "> Project Outcomes and Deliverables ……………………………………….…………6 1.9 Novelty of Work …………………………………………………………..….………6 CHAPTER 2 - REQUIREMENT ANALYSIS 2.1</span><span id="n40" class="tooltip null_selection" title=" "> Literature Survey …………………………………………………………….....……7 2.1.1 Theory Associated with Problem Area ……………………………………...…7 2.1.2 Existing Systems and Solutions …………………………………………...……7</span><span id="n41" class="tooltip null_selection" title=" "> 2.1.3 Research Findings for Existing Literature ……………………………...………8 2.1.4 The Problem That Has Been Identified ……………….……………...………...8 2.1.5<br /><br /></span><span id="n42" class="tooltip null_selection" title=" "> Survey of Tools and Technologies Used……………………………………...…9 2.2 Standards ………………………………………………………………………...……9 2.3 Software Requirements Specification ……………………………………...…………9</span><span id="n43" class="tooltip null_selection" title=" "> 2.3.1 Introduction …………………………………………………………....………..9 2.3.1.1 Purpose……………………………………………………………..……9 2.3.1.2 Intended Audience and Reading Suggestions………………………...…9 2.3.1.3</span><span id="n44" class="tooltip null_selection" title=" "> Project Scope…………………………………………………..………10 2.3.2 Overall Description…………………………………………………….....……10 v 2.3.2.1 Product Perspective………………………………….…………………10 2.3.2.2</span><span id="n45" class="tooltip null_selection" title=" "> Product Features…………………………………………..……………10 2.3.3 External Interface Requirements……………………………………….………11 2.3.3.1 User Interfaces…………………………………………………....……11 2.3.3.2<br /><br /></span><span id="n44" class="tooltip null_selection" title=" "> Hardware Interfaces……………………………………………....……11 2.3.3.3 Software Interfaces …………………………………………....………11 2.3.4 Other Non-functional Requirements ……………………………………..……11 2.3.4.1</span><span id="n47" class="tooltip null_selection" title=" "> Performance Requirements……………………………………….……11 2.3.4.2 Safety Requirements………………………………………...…………11 2.3.4.3 Security Requirements…………………………………………………12 2.4</span><span id="n48" class="tooltip null_selection" title=" "> Cost Analysis ………………………………………………………………....……..12 2.5 Risk Analysis…………………………………………………………………..…….12 CHAPTER 3 – METHODOLOGY ADOPTED 3.1 Investigative Techniques ……………………………………………………….……13</span><span id="n49" class="tooltip null_selection" title=" "> 3.2 Proposed Solution ………………………………………………………...…………14 3.3 Work Breakdown Structure ………………………………………….………………14 3.4 Tools and Technologies Used …………………………………………….…………15</span><span id="n50" class="tooltip null_selection" title=" "> CHAPTER 4 - DESIGN SPECIFICATIONS 4.1 System Architecture …………………………………………………………....……16 4.2 Design Level Diagrams ……………………………………………………...………16 4.3<br /><br /></span><span id="n51" class="tooltip null_selection" title=" "> User Interface Diagrams ……………………………………………………….……23 CHAPTER 5 – IMPLEMENTATION AND EXPERIMENTAL RESULTS 5.1 Experimental Setup …………………………………………………………....……24 5.2</span><span id="n52" class="tooltip null_selection" title=" "> Experimental Analysis ………………………………………………………....……25 5.2.1 Data……………………………………………………………………….……25 5.2.2 Performance Parameters…………………………………….…………………25 5.3</span><span id="n53" class="tooltip null_selection" title=" "> Working of the project ………………………………………………………………25 5.3.1 Procedural Workflow………………………………………………………..…25 5.3.2 Algorithmic Approaches Used………………………………………....………26 5.3.3</span><span id="n54" class="tooltip null_selection" title=" "> Project Deployment ……………………………………………………..……27 5.3.4 System Screenshots ……………………………………………………...……29 5.4 Testing Process ……………………………………………...………………………30 5.4.1<br /><br /></span><span id="n55" class="tooltip null_selection" title=" "> Test Plan …………………………………………………...………………….30 5.4.1.1 Features to be tested ……………………………………..……………30 5.4.1.2 Test Strategy ……………………………………………………..……31 5.4.1.3</span><span id="n56" class="tooltip null_selection" title=" "> Test Techniques ……………………….………………………………31 5.4.2 Test Cases ………………………………………………………….……31 v i 5.4.3 Test Results ………………………………………………...……………33 5.5 Results and Discussions……………………………...………………………………33</span><span id="n57" class="tooltip null_selection" title=" "> 5.6 Inferences Drawn ……………………………………....……………………………33 5.7 Validation of Objectives …………………………………………………………..…34 CHAPTER 6: CONCLUSIONS AND FUTURE DIRECTIONS 6.1</span><span id="n58" class="tooltip null_selection" title=" "> Conclusions …………………………………………………....…………………….35 6.2 Environmental, Economic and Societal Benefits ………………...…………………35 6.3 Reflections ……………………………………….…………………………………35</span><span id="n59" class="tooltip null_selection" title=" "> 6.4 Future Work ………………………………………………………....………………35 CHAPTER 7: PROJECT METRICS 7.1 Challenges Faced ………………………………....…………………………………36 7.2 Relevant Subjects …………………………………………………………...………36</span><span id="n60" class="tooltip null_selection" title=" "> 7.3 Interdisciplinary Knowledge Sharing ………………………………….……………37 7.4 Peer Assessment Matrix …………………………………………….………………38 7.5 Role Playing and Work Schedule …………………………………………...………38</span><span id="n61" class="tooltip null_selection" title=" "> 7.6 Student Outcomes Description and Performance Indicators …………………..……39 7.7 Brief Analytical Assessment ……………………………………………....………...41 APPENDIX A: REFERENCES …………………………………………….………………....42<br /><br /></span><span id="n62" class="tooltip null_selection" title=" "> APPENDIX B: PLAGIARISM REPORT…………………………………...………………..43 v i L I S T O F T A B L E S Table No. Caption Page No.</span><span id="n63" class="tooltip null_selection" title=" "> Table 1 Constraints 5 Table 2 Assumptions 5 Table 3 Research Findings 8 Table 4 Peer Assessment Matrix 40 Table 5 SO & PI(A-K Mapping) 41-43 v i i i L I S T O F</span><span id="n64" class="tooltip red_selection" title=" "> F I G U R E S Figure No. Caption Page No.</span><span id="n65" class="tooltip null_selection" title=" "> Figure 1 Using 3-D Algebra of positions of all entries 13 Figure 2 Methodology used 14 Figure 3 Work-BreakDown Structure 15 Figure 4 System Architecture 16 Figure</span><span id="n66" class="tooltip null_selection" title=" "> 5 ER Diagram 16 Figure 6 Sequence Diagram 17 Figure 7 Class Diagram 17 Figure 8 State Chart Diagram 18 Figure 9 Use Case #1 18 Figure 10 Use Case #2 19 Figure 11</span><span id="n67" class="tooltip null_selection" title=" "> Use Case #3 19 Figure 12 UML Component Diagram 20 Figure 13 Conceptual Architecture of the system 20 Figure 14 Object Detection Architecture 21 Figure 15 Architecture</span><span id="n68" class="tooltip null_selection" title=" "> of Moving Bot 21 Figure 16 Connection Architecture 22 Figure 17 System Architecture 22 Figure 18 User Interface Diagram 23 Figure 19 Simulation model of the Experimental</span><span id="n69" class="tooltip null_selection" title=" "> setup 24 Figure 20 Procedural Workflow Diagram 25 Figure 21 Example rectangle features shown relative to the enclosing 26 Figure 22 Robo car which will stop the</span><span id="n70" class="tooltip null_selection" title=" "> ball 27 Figure 23 Wireless Camera system with stand 28 Figure 24 Both ball and car are placed for testing to begin 28 Figure 25 System screenshot of Object detection</span><span id="n71" class="tooltip null_selection" title=" "> 29 i x Figure 26 Console Screenshot of the object’s instantaneous location 29 Figure 27 System screenshot of arduino IDE 30 Figure 28 Car is stationary as the ball</span><span id="n72" class="tooltip null_selection" title=" "> has not moved 31 Figure 29 The ball and car both move 32 Figure 30 Car successfully catches the ball 32 x L I S T O F A B B R E V I A T I O N S CNN Convolutional</span><span id="n73" class="tooltip null_selection" title=" "> Neural Network OpenCV Open source computer vision DIP Digital Image Processing API Application Programming Interface UTF Unicode Transformation Format KLT Kanade-Lucas-Tomashi</span><span id="n74" class="tooltip null_selection" title=" "> MOSSE Minimum Output Sum of Squared Error MIL Matrox Imaging Library KCF Kernelized Correlation Filter TLD Tracking, learning and detection GOTURN Generic Object</span><span id="n75" class="tooltip null_selection" title=" "> Tracking Using Regression Networks CSRT Channel and Spatial Reliability Tracker UI User Interface DRDO Defence Research and Development Organisation WAP Wireless</span><span id="n76" class="tooltip null_selection" title=" "> Application Protocol USB Universal Serial Bus AI Artificial Intelligence ML Machine Learning Wi-Fi Wireless Fidelity PPE Prediction, Planning and Execution TCP Transport</span><span id="n77" class="tooltip null_selection" title=" "> Control Protocol x i I N T R O D U C T I O N 1 .<br /><br /></span><span id="n78" class="tooltip null_selection" title=" "> 1 P r o j e c t O v e r v i e w Object Tracking using OpenCV (C++/Python) What is Object Tracking? Simply put, locating an object in successive frames of a video</span><span id="n79" class="tooltip null_selection" title=" "> is called tracking.</span><span id="n80" class="tooltip null_selection" title=" "> The definition seems straightforward but in computer vision and machine learning, tracking is a very broad term that incorporates ideologically similar but technically</span><span id="n81" class="tooltip null_selection" title=" "> different ideas. For example, all different but related views are typically studied under object tracking and detection.<br /><br /></span><span id="n13" class="tooltip red_selection" title=" "> Dense Optical flow These algorithms help in estimating the motion vector of every pixel in a video frame.</span><span id="n13" class="tooltip red_selection" title=" "> Sparse optical flow: These algorithms, such as the Kanade-Lucas-Tomashi (KLT) feature tracker, track the location of certain feature points in an image.</span><span id="n13" class="tooltip red_selection" title=" "> Kalman Filtering: A very popular signal processing algorithm is used to predict the location of a moving object based on previous motion information.</span><span id="n15" class="tooltip red_selection" title=" "> One of the earliest applications of this algorithm was missile guidance! As noted here, "the on-board computer directing the descent of the Apollo 11 lunar module</span><span id="n86" class="tooltip null_selection" title=" "> on the moon had a Kalman filter". Mean-shift and Camshaft: These are algorithms to find the maximum range of a density function. They are also used for tracking.<br /><br /></span><span id="n15" class="tooltip red_selection" title=" "> Single object trackers: In this class of trackers, the first frame is marked using a rectangle to indicate the location of the object we want to track.</span><span id="n15" class="tooltip red_selection" title=" "> The object is tracked in subsequent frames using a tracking algorithm. In most real-life applications, these trackers are used in conjunction with an object detector.</span><span id="n89" class="tooltip null_selection" title=" "> Multiple object track finding algorithms: In such cases when we have a fast object detector, it makes sense to detect multiple objects in each frame and then run</span><span id="n15" class="tooltip red_selection" title=" "> a track finding algorithm which identifies which rectangle in which frame is the one in the next frame. Corresponds to the rectangle.<br /><br /></span><span id="n91" class="tooltip null_selection" title=" "> Tracking and Detection If you've ever played with OpenCV face detection, you know that it works in real-time and you can easily detect faces in every frame.</span><span id="n92" class="tooltip null_selection" title=" "> So, why do you need tracking in the first place? Let's explore the various reasons you want to track the objects in the video, not just the repeated detection.</span><span id="n93" class="tooltip red_selection" title=" "> Tracking is faster than detection: Tracking algorithms are generally faster than detection algorithms. The reason is simple.</span><span id="n94" class="tooltip null_selection" title=" "> When you are tracking an object that was found in a previous frame, you know a lot about the object's presence.<br /><br /></span><span id="n95" class="tooltip null_selection" title=" "> You also know the location and direction of motion in the previous frame.</span><span id="n96" class="tooltip red_selection" title=" "> Therefore in the next frame, you can predict the location of the object in the next frame using all this information and do a small search 1 around the expected</span><span id="n97" class="tooltip null_selection" title=" "> location of the object to find out the correct position of the object.</span><span id="n96" class="tooltip red_selection" title=" "> A good tracking algorithm will use all the information about the object up to that point, while a detecting algorithm always starts from scratch.<br /><br /></span><span id="n99" class="tooltip null_selection" title=" "> Therefore, when designing an efficient system the detection of an object is usually run on each NT frame, while tracking algorithms are employed in between n-1 frames.</span><span id="n100" class="tooltip null_selection" title=" "> Why don't we locate the object in the first frame and track it later? It is true that tracking benefits from additional information, but you can lose track of an</span><span id="n101" class="tooltip null_selection" title=" "> object even when they go behind an obstacle for an extended period of time or if they move so fast that the tracking algorithm Can not catch.</span><span id="n96" class="tooltip red_selection" title=" "> It is also common to accumulate errors for tracking algorithms, and the bounding box that tracks the object slowly moves away from the object it is tracking.<br /><br /></span><span id="n96" class="tooltip red_selection" title=" "> To fix these problems with the tracking algorithm, a detection algorithm is run each time. Detection algorithms are trained on a large number of object instances.</span><span id="n104" class="tooltip null_selection" title=" "> Therefore, they have more knowledge about the general class of the object.</span><span id="n105" class="tooltip null_selection" title=" "> On the other hand, tracking algorithms know more about the specific instance of the class they are tracking.</span><span id="n96" class="tooltip red_selection" title=" "> Tracking can help if it fails to detect: If you are running a face detector on a video and the person's face collides with an object, the face detector will most</span><span id="n93" class="tooltip red_selection" title=" "> likely fail. A good tracking algorithm, on the other hand, will handle some level of occlusion. In the video below, you can see the author of MIL tracker Dr.<br /><br /></span><span id="n108" class="tooltip null_selection" title=" "> Boris can look at Babenko to see how the MIL tracker works as a snag.</span><span id="n109" class="tooltip null_selection" title=" "> Tracking preserves identity The output of object detection is an array of rectangles that contain an object.</span><span id="n110" class="tooltip null_selection" title=" "> However, there is no identification associated with the object.</span><span id="n111" class="tooltip null_selection" title=" "> For example, in the video below, a detector that detects red dots will produce rectangles corresponding to all the dots it has detected in one frame.<br /><br /></span><span id="n112" class="tooltip null_selection" title=" "> In the next frame, it will produce another array of rectangles.</span><span id="n113" class="tooltip null_selection" title=" "> In the first frame, a particular point can be represented by a rectangle at position 10 in the array and in the second frame, it can be at position 17.</span><span id="n114" class="tooltip null_selection" title=" "> When using detection on the frame we do not know to which object the rectangle corresponds. On the other hand, tracking literally provides a way to connect the dots.</span><span id="n115" class="tooltip null_selection" title=" "> OpenCV 3 Tracking API OpenCV 3 comes with a new tracking API that has an implementation of multiple single object tracking algorithms. OpenCV 3.4.1<br /><br /></span><span id="n116" class="tooltip red_selection" title=" "> has 8 different trackers available - BOOSTING, MIL, KCF, TLD, MEDIANFLOW, GOTURN, MOSSE and CSRT. Note: OpenCV 3.2</span><span id="n114" class="tooltip red_selection" title=" "> has implementations of these 6 trackers - BOOSTING, MIL, TLD, MEDIANFLOW, MOSSE and GOTURN. There are implementations of these 5 trackers in OpenCV 3.1</span><span id="n118" class="tooltip null_selection" title=" "> - BOOSTING, MIL, KCF, TLD, MEDIANFLOW. OpenCV 3.0 has implementations of the following 4 trackers - BOOSTING, MIL, TLD, MEDIANFLOW. Update: In OpenCV 3.3,</span><span id="n119" class="tooltip null_selection" title=" "> the tracking API has changed. Checks the code for the version and then uses the corresponding API.<br /><br /></span><span id="n120" class="tooltip null_selection" title=" "> 2 Before we provide a brief description of the algorithm, let us look at the setup and usage.</span><span id="n121" class="tooltip null_selection" title=" "> In the comment code below we first set up the tracker by selecting a tracker type - Bosting, MIL, KCF, TLD, Medianflow, Gothorn, Mosey or CSRT.</span><span id="n122" class="tooltip null_selection" title=" "> We then open a video and hold a frame.</span><span id="n123" class="tooltip null_selection" title=" "> We define a bounding box containing the object for the first frame and initialize the tracker with the first frame and the bounding box.<br /><br /></span><span id="n124" class="tooltip null_selection" title=" "> Finally, we read the frame from the video and update the tracker in a loop to get a new bounding box for the current frame. Results are displayed later. 1 .</span><span id="n125" class="tooltip null_selection" title=" "> 2 N e e d A n a l y s i s Our Autonomous goalkeeper can be generalized as an Autonomous target interceptor. It has a number of uses in sports and entertainment industry.</span><span id="n126" class="tooltip null_selection" title=" "> But most importantly it can be used in defense to develop Ballistic missiles and target interceptor for the Indian forces.</span><span id="n127" class="tooltip null_selection" title=" "> Currently, the technology is under research by DRDO.<br /><br /></span><span id="n128" class="tooltip null_selection" title=" "> This technology has already been developed by Israeli military to counter any Arabic missiles and Palestinians attacks.</span><span id="n129" class="tooltip null_selection" title=" "> To develop it in 3d is close to impossible thus, our group is trying to make it in 2d as a first step to improve the technology.</span><span id="n130" class="tooltip null_selection" title=" "> The main requirements to make it a success are: a. The Bot(goalkeeper) must have a motor that can allow the bot to move quickly. b.</span><span id="n131" class="tooltip red_selection" title=" "> A camera that can record the ball movement in at least 40Fps. c.<br /><br /></span><span id="n132" class="tooltip null_selection" title=" "> The camera must employ a raspberry Pi to process the live feed, we can also transfer the live feed to laptop computer via Bluetooth or Wi-Fi. d.</span><span id="n133" class="tooltip null_selection" title=" "> The computer (laptop / raspberry pi) must compute the predicted the landing point for the ball and must instruct the bot to move accordingly. e.</span><span id="n134" class="tooltip null_selection" title=" "> The computer will communicate with the bot through a wireless communication device namely, ZigBee.</span><span id="n135" class="tooltip null_selection" title=" "> To elaborate on this point, this ball tracker or live object tracker model can be used in various other fields. Such as in prisons to keep track of all the prisoners.<br /><br /></span><span id="n136" class="tooltip null_selection" title=" "> In Zoos, to keep track of all the animals, especially animals like Lions and Tigers.</span><span id="n137" class="tooltip null_selection" title=" "> It can be used in Self driving cars to track the objects in the front to take actions if necessary.</span><span id="n138" class="tooltip null_selection" title=" "> There can be an infinite number of fields where this technology can be used. 1 .</span><span id="n139" class="tooltip null_selection" title=" "> 3 R e s e a r c h G a p s As of now, our project is to develop a live object tracker and real time tracker.<br /><br /></span><span id="n140" class="tooltip null_selection" title=" "> Our aim includes technologies like Python, machine learning, artificial intelligence, OpenCV and Arduino.</span><span id="n141" class="tooltip null_selection" title=" "> To mention the research gap currently present, we can say individual developers have been successful in developing certain technologies required to make this project</span><span id="n142" class="tooltip null_selection" title=" "> however there are still some things that have not developed , for instance the live object 3 tracker has to be trained under the constraint that the background will</span><span id="n143" class="tooltip red_selection" title=" "> remain the same and will not change during the course of the target’s movement.<br /><br /></span><span id="n144" class="tooltip null_selection" title=" "> Also the bot that our team is working on required very high technology that has not been developed yet.</span><span id="n145" class="tooltip null_selection" title=" "> To make our project work in 3d, it will require spring configuration and jump control which is still in research at Cambridge and other foreign optimized.</span><span id="n146" class="tooltip null_selection" title=" "> The AI ?? Gap study, a PYMNTS and Brighton collaboration, analyzes survey response data from more than 200 financial executives from commercial banks, community</span><span id="n147" class="tooltip red_selection" title=" "> banks, and credit unions across the United States to provide comprehensive information on how financial institutions leverage AI and ML technology gives.<br /><br /></span><span id="n147" class="tooltip red_selection" title=" "> Optimize your businesses. For this, we collected over 12,000 data points on financial institutions with assets ranging from $ 1 billion to over $ 100 billion.</span><span id="n149" class="tooltip null_selection" title=" "> This report details the results of our extensive research. Key Findings from the research include: 70.5% part of Fis that used data mining to fight fraud 4.1</span><span id="n149" class="tooltip red_selection" title=" "> Average number of algorithmic things used by banks with more than $100 billion in assets 2.5% Share of Fis that used AI systems to empower payments services 1 .</span><span id="n151" class="tooltip null_selection" title=" "> 4 P r o b l e m D e f i n i t i o n a n d S c o p e Our Group is determined to design an Autonomous goalkeeper capable of intercepting balls that are aimed towards</span><span id="n152" class="tooltip null_selection" title=" "> the goal post, the keeper is programmed to protect. The Project involves a number of state-of-the-Art technologies like ball tracking and motorized optimized movement.<br /><br /></span><span id="n153" class="tooltip null_selection" title=" "> Our design will only work in 2 dimensions. We will employ a number of Machine learning algorithms and image processing algorithms.</span><span id="n154" class="tooltip red_selection" title=" "> In this project we present the design and implementation of our Small Size Robotic Soccer Goalkeeper.</span><span id="n155" class="tooltip null_selection" title=" "> We explain the three main components of our architecture: Vision System, AI System and Robots.</span><span id="n156" class="tooltip null_selection" title=" "> Each element is an independent entity and therefore the explanation focuses on the improvements made to our object tracking techniques and the way these changes</span><span id="n157" class="tooltip red_selection" title=" "> interact with the rest of the elements in the architecture. Keywords: Small-size, robo-football, autonomous, vision, architecture.<br /><br /></span><span id="n158" class="tooltip null_selection" title=" "> The final project will include a camera module optimized to a frame rate that will be transferred to the computer immediately and a machine learning algorithm drafted</span><span id="n159" class="tooltip null_selection" title=" "> in Python 3 that will take in frame recorded from the camera and will determine its locations and angle, speed with respect to the previous location.</span><span id="n160" class="tooltip null_selection" title=" "> The angle and speed calculated will be stored in a database that will be used to predict the final landing point of the ball.</span><span id="n161" class="tooltip null_selection" title=" "> The Python program will trigger the Arduino program that will calculate the distance, speed and direction of the bot required to stop the ball from hitting the target.<br /><br /></span><span id="n162" class="tooltip null_selection" title=" "> The instructions will be transferred to the bot via a zigbee and the bot will execute the instructions with the help of an Arduino attached to it.</span><span id="n163" class="tooltip null_selection" title=" "> The bot will be made by reverse engineering a wireless remote controlled car or will be designed from scratch with a high speed motor at the very base. 4 1 .</span><span id="n164" class="tooltip null_selection" title=" "> 5 A s s u m p t i o n s a n d C o n s t r a i n t s T A B L E 1 : C o n s t r a i n t s S . N o .</span><span id="n165" class="tooltip null_selection" title=" "> C o n s t r a i n t s 1 T h e B a l l s h o t b y t h e p l a y e r m u s t n o t g a i n a n y h e i g h t , t h a t i s , t h e d e s i g n w i l l w o r k o n</span><span id="n166" class="tooltip null_selection" title=" "> l y i n t w o d i m e n s i o n s a n d n o t i n 3 d i m e n s i o n s .<br /><br /></span><span id="n167" class="tooltip null_selection" title=" "> 2 T h e r e m u s t b e a m i n i m u m l a g b e t w e e n t h e l i v e f e e d o f t h e b a l l ’ s m o v e m e n t a n d t h e f i n a l m a c h i n e l e a</span><span id="n166" class="tooltip null_selection" title=" "> r n i n g p r e d i c t i o n o f t h e b a l l ’ s l a n d i n g p o s i t i o n . T A B L E 2 : A s s u m p t i o n s S . N o .</span><span id="n165" class="tooltip null_selection" title=" "> A s s u m p t i o n s 1 T h e B a l l w i l l m o v e i n 2 d i m e n s i o n s o n l y , i . e T h e r e w i l l n o t b e a n y h e i g h t i n v o l v e d .</span><span id="n170" class="tooltip null_selection" title=" "> 2 S i n c e t h e a c c e l e r a t i o n b y t h e m o t o r w i l l g i v e r i s e t o u n p r e d i c t a b l e e r r o r , w e w i l l a s s u m e t h a t m</span><span id="n171" class="tooltip null_selection" title=" "> o t o r w i l l h a v e n o a c c e l e r a t i o n .<br /><br /></span><span id="n172" class="tooltip null_selection" title=" "> 3 T h e s p e e d o f t h e b a l l w i l l n o t e x c e e d a c e r t a i n m a x i m u m s p e e d d u e t o t e c h n i c a l l i m i t a t i o n s o f c o m</span><span id="n173" class="tooltip null_selection" title=" "> p u t e r .</span><span id="n166" class="tooltip null_selection" title=" "> 4 T h e b a l l w i l l b e m o v i n g o n a p l a i n , u n i f o r m f r i c t i o n s u r f a c e a n d s u r f a c e w i l l b e o f u n i f o r m c o l o r</span><span id="n175" class="tooltip null_selection" title=" "> t o e a s e t h e i m a g e p r o c e s s i n g c o m p u t a t i o n s .<br /><br /></span><span id="n176" class="tooltip null_selection" title=" "> 5 T h e b a l l w i l l b e o f s p h e r i c a l s h a p e , o f t e n n i s b a l l ’ s s i z e a n d n o t o f a n y o t h e r s h a p e o r s i z e .</span><span id="n177" class="tooltip null_selection" title=" "> 6 T h e l i v e f e e d w i l l h a v e s o m e d e l a y a n d f r a m e s t u t t e r i n g . 1 .</span><span id="n178" class="tooltip null_selection" title=" "> 6 A p p r o v e d O b j e c t i v e s The aim of the project is to design an Autonomous goalkeeper System such that: • The system will be able to successfully detect</span><span id="n179" class="tooltip null_selection" title=" "> the presence of the ball in live camera feed. • The system should be able to accurately predict the future location of the ball.<br /><br /></span><span id="n180" class="tooltip null_selection" title=" "> • The system should be able to control the bot properly with commands. • The goalkeeper bot shall be able to intercept the football before it hits the goal post.</span><span id="n181" class="tooltip null_selection" title=" "> • The camera-computer combination will be able to track the ball’s position accurately and predict its route.</span><span id="n182" class="tooltip null_selection" title=" "> • The bot will have high speed motor to ensure quick movement. 5 1 .</span><span id="n183" class="tooltip null_selection" title=" "> 7 M e t h o d o l o g y U s e d Use State of the art object tracking technology to track the movement of the ball shot by the player.<br /><br /></span><span id="n184" class="tooltip null_selection" title=" "> • Employ a camera that will transfer the live feed of the ball’s movement to the computer.</span><span id="n185" class="tooltip null_selection" title=" "> • The computer will predict the most probable final landing position of the ball by employing various machine learning, neural networks and image processing technologies.</span><span id="n186" class="tooltip null_selection" title=" "> • The computer will ascertain the bot’s current location and accordingly compute the direction and time in which the bot must move to intercept the target or the</span><span id="n187" class="tooltip null_selection" title=" "> ball. • The bot will communicate with the computer through a Zigbee. • The bot will employ an Arduino that will provide all the control signals. 1 .<br /><br /></span><span id="n188" class="tooltip null_selection" title=" "> 8 P r o j e c t O u t c o m e s a n d D e l i v e r a b l e s There are various outcomes to this project: • The player or the user will kick or strike the ball.</span><span id="n179" class="tooltip null_selection" title=" "> • The ball will be tracked by the camera-computer arrangement, • An ML model which will be used to compute the final landing position of the ball.</span><span id="n190" class="tooltip null_selection" title=" "> • A computer will communicate with the goalkeeper bot and order it move accordingly so as to intercept the ball before it hits the target.</span><span id="n191" class="tooltip null_selection" title=" "> • The computer program will assume that the bot has successfully intercepted the target and will loop to the beginning again. 1 .<br /><br /></span><span id="n192" class="tooltip null_selection" title=" "> 9 N o v e l t y o f W o r k Many individual developers have made strives in this field, ie. Object tracking.</span><span id="n193" class="tooltip null_selection" title=" "> However, no one has yet combined all the progress into one massive project that works in real time.</span><span id="n194" class="tooltip null_selection" title=" "> The project is unique to an extent, the field of object tracking is very old, it was first introduced in the 1980s as a sub-part of Artificial intelligence but remains</span><span id="n195" class="tooltip null_selection" title=" "> theoretical till date,no one has made strides to make a working project that involves arduino, zigbee, artificial intelligent Bot and ball tracking.<br /><br /></span><span id="n196" class="tooltip null_selection" title=" "> 6 R E Q U I R E M E N T A N A L Y S I S 2 . 1 L i t e r a t u r e S u r v e y 2.1.1</span><span id="n197" class="tooltip red_selection" title=" "> Theory Associated with Problem Area Interception (approaching a moving object until collision) and tracking (approaching a moving object while matching its location</span><span id="n198" class="tooltip null_selection" title=" "> and velocity) are important tasks in a wide range of applications, such as robotic soccer and automated surveillance.</span><span id="n199" class="tooltip null_selection" title=" "> In addition, they represent a challenging test bed for the integration of various technologies including image processing, filtering, control theory, and AI strategies.<br /><br /></span><span id="n200" class="tooltip red_selection" title=" "> Interception and tracking have been largely addressed in the literature based on targeted motion characteristics as well as robot kinematic. And dynamic models.</span><span id="n200" class="tooltip red_selection" title=" "> The instantaneous target location and velocity can be known in advance as part of a reference trajectory or can be estimated and inferred through sensory data. 2.1.2</span><span id="n202" class="tooltip null_selection" title=" "> Existing Systems and Solutions A common strategy known as PPE (prediction, planning, and execution) focuses on time-optimal blocking, possible when the target speed</span><span id="n203" class="tooltip null_selection" title=" "> is fully (or substantially) already known; In this case, the problem is essentially planning a robotic trajectory leading to a suitable trajectory.<br /><br /></span><span id="n204" class="tooltip red_selection" title=" "> For example, a time-optimal technique for free-flying interceptors and targets.</span><span id="n205" class="tooltip null_selection" title=" "> Such an approach can be extended to manipulations to achieve smooth grasping inhibition with terminal-well matching by pairing with traditional tracking methods.</span><span id="n197" class="tooltip red_selection" title=" "> An active PPE technique for the 6-dof manipulator is designed to improve the basic PPE strategy.</span><span id="n207" class="tooltip null_selection" title=" "> When the target speed is not already known and / or can change abruptly, it is necessary to rely on some kind of estimate of its position and velocity coming from</span><span id="n204" class="tooltip red_selection" title=" "> the sensor data. A particularly interesting situation is the use of visual feedback.<br /><br /></span><span id="n209" class="tooltip null_selection" title=" "> In the position-based visual servo, the target pose is estimated based on visual data and geometric models.</span><span id="n210" class="tooltip null_selection" title=" "> For example, a ubiquitous indirect vision system is used to determine robot posture from feature extraction, so that the basic tasks of a robot goalkeeper can be</span><span id="n211" class="tooltip null_selection" title=" "> accomplished in terms of trajectory and posture stabilization. In this context, Kalman filtering is often used to derive a strong prediction of target motion.</span><span id="n212" class="tooltip null_selection" title=" "> In image-based visual servings, the spatial relationship between the target and the robot camera is directly estimated on the image plane, and the error signal is</span><span id="n213" class="tooltip null_selection" title=" "> expressed in terms of image features.<br /><br /></span><span id="n214" class="tooltip null_selection" title=" "> Originally developed for robotic manipulators equipped with eye-in-hand systems, image-based visual servos have also been applied to non-economic vehicles such as</span><span id="n215" class="tooltip null_selection" title=" "> wheel mobile robots. 7 2.1.3 Research Findings for Existing Literature T A B L E 3 : R e s e a r c h F i n d i n g s S . N o .</span><span id="n216" class="tooltip null_selection" title=" "> R o l l N u m b e r N a m e P a p e r T i t l e T o o l s / T e c h n o l o g y F i n d i n g s C i t a t i o n 1 1 0 1 6 0 3 3 6 4 U t k a r s h C h u g h V i s</span><span id="n217" class="tooltip null_selection" title=" "> u a l S e r v o i n g o f W h e e l e d M o b i l e R o b o t f o r I n t e r c e p t i n g a M o v i n g O b j e c t .<br /><br /></span><span id="n165" class="tooltip null_selection" title=" "> C a m e r a , B a l l T r a c k i n g A l g o r i t h m T h e r e q u i r e d r e s o l u t i o n a n d f r a m e r a t e t o t r a c k m o v i n g b a l l .</span><span id="n219" class="tooltip red_selection" title=" "> A g i n , G . J .</span><span id="n220" class="tooltip null_selection" title=" "> [ 4 ] 2 1 0 1 6 0 3 3 6 4 U t k a r s h C h u g h M e c h a t r o n i c D e s i g n o f S o c c e r R o b o t f o r t h e S m a l l - S i z e L e a g u e ( R o b</span><span id="n166" class="tooltip null_selection" title=" "> o C u p ) C o n s t r u c t i o n o f s o c c e r b o t T h e r e q u i r e d c o n f i g u r a t i o n o f m o t o r s ( r p m ) S a n d e r s o n [ 7 ] 3 1 0 1</span><span id="n222" class="tooltip null_selection" title=" "> 6 1 0 0 9 3 V a i b h a v S o o d R o b o t G o a l K e e p e r P y t h o n , I m a g e P r o c e s s i n g u s i n g M A T L A B , A r d u i n o , M o t o r s O</span><span id="n166" class="tooltip null_selection" title=" "> b j e c t t r a c k i n g a l g o r i t h m i m p l e m e n t a t i o n u s i n g P y t h o n W a t a n a b e [ 5 ] 4 1 0 1 6 1 0 0 9 3 V a i b h a v S o o d R e</span><span id="n166" class="tooltip null_selection" title=" "> a l t i m e O p e n C V B a l l T r a c k e r P y t h o n , O p e n C V O b j e c t t r a c k i n g a l g o r i t h m i m p l e m e n t a t i o n u s i n g P y t</span><span id="n225" class="tooltip null_selection" title=" "> h o n A n d e r s o n , P e t e r s o n , S h e n k e r , T u r n e r [ 1 ] 5 1 0 1 6 1 0 0 9 1 T a r a n j e e t S i n g h A r d u i n o c o n t r o l l e d R o</span><span id="n226" class="tooltip null_selection" title=" "> b o c a r A r d u i n o , B l u e t o o t h , R C C a r , W i r e l e s s C o m m u n i c a t i o n A s s e m b l i n g t h e R C C a r a n d r u n n i n g i t u</span><span id="n227" class="tooltip null_selection" title=" "> s i n g A r d u i n o A l - H u s s e i n y , A p p e l g r e n , M u s t i n i [ 3 ] 6 1 0 1 6 1 1 0 5 7 T u s h a r M a h a j a n S m a l l S i z e S o c c e r</span><span id="n228" class="tooltip null_selection" title=" "> R o b o t s C a m e r a N e t w o r k O b j e c t T r a c k i n g t e c h n i q u e s c u r r e n t l y i n u s e C h a u m e t t e , H u t c h i n s o n [ 6 ] 7</span><span id="n166" class="tooltip null_selection" title=" "> 1 0 1 6 1 1 0 5 7 T u s h a r M a h a j a n C o n t r o l l e r D e s i g n f o r H i g h - P e r f o r m a n c e V i s u a l S e r v o i n g C a m e r a C o n f</span><span id="n230" class="tooltip null_selection" title=" "> i g u r a t i o n , R o b o t C o n f i g u r a t i o n O b j e c t T r a c k i n g f o r h i g h s p e e d m o v i n g o b j e c t s . D u n c a n [ 2 ] 2.1.4<br /><br /></span><span id="n231" class="tooltip null_selection" title=" "> The Problem That Has Been Identified The problem identified in literature survey is that in most of the surveys, high end devices are used which are not easily available</span><span id="n232" class="tooltip null_selection" title=" "> in the current market and are too expensive to be used in our project.</span><span id="n233" class="tooltip null_selection" title=" "> Moreover, some surveys have used a ready-made soccer-bot with built-in wheeled motors and camera.</span><span id="n234" class="tooltip null_selection" title=" "> The actual tracking algorithm and the technology used are not mentioned in any of the survey. Only the essence behind tracking the ball is discussed. 8 2.1.5<br /><br /></span><span id="n235" class="tooltip null_selection" title=" "> Survey of Tools and Technologies Used To carry out with the literature survey the methodology used by the members is to read all the research paper to get the wide</span><span id="n236" class="tooltip null_selection" title=" "> idea about what all the research is done till now and how the specified project is innovated by the members.</span><span id="n237" class="tooltip null_selection" title=" "> Our research is more focused on ideas rather than research paper. We used various tools ? for making literature survey: i. Web Browser to look for research papers.</span><span id="n238" class="tooltip null_selection" title=" "> ii. Mendeley for references and to manage literature. iii. Adobe Crater for making PDF. iv. Microsoft word to format and write the literature survey. 2 .<br /><br /></span><span id="n239" class="tooltip null_selection" title=" "> 2 S t a n d a r d s ? ISO 20954 – Image Stabilization standard for camera ? ISO 20490 – Auto Focus Standard for Camera ? ISO 19093 – Low Light Performance Standard</span><span id="n240" class="tooltip null_selection" title=" "> ? IEEE 802.11</span><span id="n241" class="tooltip red_selection" title=" "> – Wireless Communication ? ISO 10218-1:2011 specifies requirements and guidelines for the inherent safe design, protective measures and information for use of industrial</span><span id="n242" class="tooltip null_selection" title=" "> robots. 2 . 3 S o f t w a r e R e q u i r e m e n t s S p e c i f i c a t i o n 2.3.1 Introduction This section introduces about the project.<br /><br /></span><span id="n243" class="tooltip null_selection" title=" "> It describes about the specifications of project. It also states about requirements of the project. 2.3.1.1</span><span id="n244" class="tooltip null_selection" title=" "> Purpose This Software Requirements Specification (SRS) documents the key specifications, which describe a prototype in terms of functional and non-functional requirements</span><span id="n245" class="tooltip red_selection" title=" "> for autonomous documentation. The documented information helps the intended audience to design and develop the product.</span><span id="n246" class="tooltip null_selection" title=" "> We are launching an official prototype version and modifying it according to user needs. 2.3.1.2<br /><br /></span><span id="n247" class="tooltip null_selection" title=" "> Intended Audience and Reading Suggestions The primary readers of this document are IoT researchers, software and hardware developers, and intended audiences.</span><span id="n248" class="tooltip null_selection" title=" "> This document is for: Developers: To be assured they are developing the right project meeting the requirements provided in this project.</span><span id="n249" class="tooltip null_selection" title=" "> Examiner: To keep an accurate list of features and functions, which will react according to requirements and diagrams provided.</span><span id="n250" class="tooltip red_selection" title=" "> Documentation Author: To know what features and how they will explain. What technologies are required, how the system will respond to each user's action, etc.<br /><br /></span><span id="n251" class="tooltip null_selection" title=" "> 9 System Administrator: Correct input and output and feedback in error situations to know what they would expect from the system. 2.3.1.3</span><span id="n252" class="tooltip null_selection" title=" "> Project Scope The scope of this project will be to produce a product that allows real time target tracking and accurate target interception.</span><span id="n253" class="tooltip null_selection" title=" "> If developed further, this project can be utilized by Sportsmen like football players, rugby players and cricketers mainly for the purpose of training and practice.</span><span id="n254" class="tooltip null_selection" title=" "> This technique can be further developed to manufacture a missile interceptor for Indian Defense. A weapon that no country posses , not even USA.<br /><br /></span><span id="n255" class="tooltip null_selection" title=" "> This weapon can give any country massive advantage over its enemies. Anti- missile weapon is the ultimate protection any country can hope for.</span><span id="n256" class="tooltip null_selection" title=" "> The techniques involved in autonomous goalkeeper are very similar to techniques that will one be used to develop the ultimate anti missile project.</span><span id="n257" class="tooltip null_selection" title=" "> Currently, Israel is the only country that has openly invested in this project and even has developed a working prototype with respectable accuracy and hit scores.</span><span id="n258" class="tooltip null_selection" title=" "> 2.3.2 Overall Description The description about the project is mentioned below under different sections.<br /><br /></span><span id="n259" class="tooltip null_selection" title=" "> The section mainly explains the product perspective and Product features. 2.3.2.1</span><span id="n260" class="tooltip null_selection" title=" "> Product Perspective As a matter of fact, sports is a multi billion dollar industry , every player professional or not strides to improve his/her performance and</span><span id="n261" class="tooltip null_selection" title=" "> most of these players are ready to pay for a device that can allow them to improve without the need of another trainer, example automatic ball throwing machine used</span><span id="n262" class="tooltip null_selection" title=" "> in baseball and cricket.<br /><br /></span><span id="n263" class="tooltip null_selection" title=" "> However, no matter how weird it may sound, there is no product available that can allow a football player to practice his/her kicks without any external help, thus</span><span id="n264" class="tooltip red_selection" title=" "> our team decided to work on this project “Autonomous Goalkeeper and object tracker”.</span><span id="n265" class="tooltip null_selection" title=" "> This project’s prototype if developed further can be used to develop a product that can allow the football players to practice without external help. 2.3.2.2</span><span id="n266" class="tooltip null_selection" title=" "> Product Features Use State of the art object tracking technology to track the movement of the ball shot by the player.<br /><br /></span><span id="n267" class="tooltip null_selection" title=" "> • Employ a camera that will transfer the live feed of the ball’s movement to the computer.</span><span id="n268" class="tooltip null_selection" title=" "> • The computer will predict the most probable final landing position of the ball by employing various machine learning, neural networks and image processing technologies.</span><span id="n269" class="tooltip null_selection" title=" "> • The computer will ascertain the bot’s current location and accordingly compute the direction and time in which the bot must move to intercept the target or the</span><span id="n270" class="tooltip null_selection" title=" "> ball. 1 0 • The bot will communicate with the computer through a Zigbee. • The bot will employ an Arduino that will provide all the control signals. 2.3.3<br /><br /></span><span id="n271" class="tooltip null_selection" title=" "> External Interface Requirements The section explains about the External interface requirements.</span><span id="n272" class="tooltip null_selection" title=" "> Under this section, Some light is shed on the user, hardware and software interfaces. 2.3.3.1</span><span id="n273" class="tooltip null_selection" title=" "> User Interfaces The User interface includes the person to hit the ball in the direction of the goalpost.</span><span id="n274" class="tooltip null_selection" title=" "> Also user can see the process of path prediction of the ball in real time by looking at the PC's screen. 2.3.3.2<br /><br /></span><span id="n275" class="tooltip red_selection" title=" "> Hardware Interfaces A hardware interface is an architecture used to interconnect two devices together.</span><span id="n275" class="tooltip red_selection" title=" "> It includes the design of the plug and socket, the type, number and purpose of the wires and the electrical signals that are passed across them.</span><span id="n277" class="tooltip null_selection" title=" "> The solution makes extensive use of several hardware devices. The camera module is connected to the PC using USB version 2.0/3.0.</span><span id="n278" class="tooltip null_selection" title=" "> The PC is connected to rc bot using wireless connection through Wi-Fi. The bot itself has connections for power supply which is done using battery. 2.3.3.3<br /><br /></span><span id="n279" class="tooltip red_selection" title=" "> Software Interfaces Software interfaces (programming interfaces) are the languages, codes and messages that programs use to communicate with each other and to the</span><span id="n280" class="tooltip null_selection" title=" "> hardware.</span><span id="n281" class="tooltip null_selection" title=" "> In this project the live video stream is transferred to a PC using machine code sending pixel values, which are in bits, in 30fps refresh rate and then PC process</span><span id="n282" class="tooltip null_selection" title=" "> the live stream.<br /><br /></span><span id="n283" class="tooltip null_selection" title=" "> We use python through which the machine learning model trains and predicts ball’s path and PC uses machine code to communicate with rc bot through wireless connection.</span><span id="n284" class="tooltip null_selection" title=" "> In RC bot also it uses information in bits 0 and 1 to tell the motors to rotate and in which direction. 2.3.4 Other Non-functional Requirements 2.3.4.1</span><span id="n285" class="tooltip null_selection" title=" "> Performance Requirements a. USB camera must get updates about the visual after a certain period. b. Goal-Keeper Bot should remain active during movement of ball.</span><span id="n286" class="tooltip null_selection" title=" "> c. Camera response time is in the range of 3ms to 5ms according to ping received. d. Using a Wireless system, Latency is minimized during capturing of frames. 2.3.4.2<br /><br /></span><span id="n287" class="tooltip null_selection" title=" "> Safety Requirements a. Bot is rubber coated to withstand any physical damage when hit by a ball. b. Ball should not be kicked at very high speed. 1 1 c.</span><span id="n288" class="tooltip null_selection" title=" "> Electricity should not be shut-off as camera would fluctuate. 2.3.4.3 Security Requirements a.</span><span id="n289" class="tooltip null_selection" title=" "> Tampering of camera should be avoided as results generated would be inaccurate. b. Data is saved directly in the database protected with password. c.</span><span id="n290" class="tooltip null_selection" title=" "> Only relevant data should be send to the server. 2 .<br /><br /></span><span id="n291" class="tooltip null_selection" title=" "> 4 C o s t A n a l y s i s USB-Camera for recording and transferring the feed live - Rs2000, RC car(required for assembling the goalkeeper) - Rs2000, Arduino(fitted</span><span id="n292" class="tooltip null_selection" title=" "> with Zigbee/Bluetooth) for receiving live commands from the Processor - Rs1000, Zigbee module -Rs980, Total cost - Rs5980/- 2 .</span><span id="n293" class="tooltip null_selection" title=" "> 5 R i s k A n a l y s i s Though our project is taken care of every causality but certainly there can be many flaws and further risks involved if not checked every</span><span id="n294" class="tooltip null_selection" title=" "> part of our project's functioning. Some of the major can be- a. Missing the information of objects in front of camera due to usage of low pixel camera b.<br /><br /></span><span id="n295" class="tooltip null_selection" title=" "> Improper Object detection after detecting them by camera due to some errors in algorithm used or some modifications may lead to mixing of objects which are closely</span><span id="n296" class="tooltip null_selection" title=" "> related such as a bottle of water and a bottle of wine. c. Sudden stoppage in working of product due to improper supply from poor quality battery used. d.</span><span id="n297" class="tooltip null_selection" title=" "> Communication error due to the use of Zigbee. e. Delay in the response time of bot because of latency in camera-computer interconnection. f.</span><span id="n298" class="tooltip null_selection" title=" "> Background may interfere with the ball causing low accuracy in object detection. 1 2 M E T H O D O L O G Y A D O P T E D 3 .<br /><br /></span><span id="n299" class="tooltip null_selection" title=" "> 1 I n v e s t i g a t i v e T e c h n i q u e s F i g u r e 1 : U s i n g 3 - D A l g e b r a o f p o s i t i o n s o f a l l e n t r i e s According to the mentioned</span><span id="n300" class="tooltip null_selection" title=" "> above techniques this project uses the descriptive technique of the investigative techniques this is because as mentioned in the descriptive technique the new models,</span><span id="n301" class="tooltip null_selection" title=" "> concepts and systems are designed. The system is designed keeping in mind that we need to stop the ball before it hits the goal post.</span><span id="n302" class="tooltip null_selection" title=" "> The main objective is to catch the ball before it hits the goal.<br /><br /></span><span id="n303" class="tooltip null_selection" title=" "> Therefore we need a system that can see and detect the ball’s position, predict its future path and ultimately make the movable rc bot to stop it.</span><span id="n304" class="tooltip null_selection" title=" "> So the system needs to be able to see the ball somehow, this could be easily done with any camera module.</span><span id="n305" class="tooltip null_selection" title=" "> The camera module would be connected to the system by either wireless or wired architecture.</span><span id="n306" class="tooltip null_selection" title=" "> The system needs to detect the ball and calculate its location relative to the frame of the camera, for this we can use existing technologies like object detection</span><span id="n307" class="tooltip null_selection" title=" "> using machine and deep learning.<br /><br /></span><span id="n308" class="tooltip null_selection" title=" "> Also we need to predict where the ball is going and what its end point will be, before it is actually able to do that so we can take action in time to stop it.</span><span id="n309" class="tooltip null_selection" title=" "> To do this we would need to use machine learning algorithms.</span><span id="n310" class="tooltip null_selection" title=" "> 1 3 After predicting the ball’s final position, system need to give instructions to the rc bot to stop it, For this we should use wireless communication like Wi-Fi.</span><span id="n311" class="tooltip null_selection" title=" "> After receiving the instructions from pc rc bot will stop the ball from hitting the ball and our objective will be complete. 3 .<br /><br /></span><span id="n312" class="tooltip null_selection" title=" "> 2 P r o p o s e d S o l u t i o n • Use State of the art object tracking technology to track the movement of the ball shot by the player.</span><span id="n313" class="tooltip null_selection" title=" "> • Employ a camera that will transfer the live feed of the ball’s movement to the computer.</span><span id="n314" class="tooltip null_selection" title=" "> • The computer will predict the most probable final landing position of the ball by employing various machine learning, neural networks and image processing technologies.</span><span id="n315" class="tooltip null_selection" title=" "> • The computer will ascertain the bot’s current location and accordingly compute the direction and time in which the bot must move to intercept the target or the</span><span id="n316" class="tooltip null_selection" title=" "> ball. • The bot will communicate with the computer through a Zigbee. • The bot will employ an Arduino that will provide all the control signals.<br /><br /></span><span id="n317" class="tooltip null_selection" title=" "> F i g u r e 2 : M e t h o d o l o g y u s e d 3 .</span><span id="n318" class="tooltip null_selection" title=" "> 3 W o r k B r e a k d o w n S t r u c t u r e A work-breakdown structure in project management and systems engineering, is a deliverable-oriented breakdown of a</span><span id="n319" class="tooltip red_selection" title=" "> project into smaller components. A work breakdown structure is a key project deliverable that organizes the team's work into manageable sections.</span><span id="n320" class="tooltip null_selection" title=" "> 1 4 The work breakdown structure for the project is given below:- F i g u r e 3 : W o r k - B r e a k D o w n S t r u c t u r e 3 .<br /><br /></span><span id="n321" class="tooltip null_selection" title=" "> 4 T o o l s a n d T e c h n o l o g i e s U s e d ? Camera module: A camera is required to give the live feed of project area to the computing device.</span><span id="n322" class="tooltip null_selection" title=" "> ? Computing device: A powerful enough computer is required to do real time object detection of the ball and predict its path.</span><span id="n323" class="tooltip null_selection" title=" "> It will also send instructions to the Arduino placed on RC car.</span><span id="n324" class="tooltip red_selection" title=" "> ? Arduino: Arduino board is composed of a microcontroller, some LEDs, a reset button, and many pins that we can use for input/output operations.<br /><br /></span><span id="n324" class="tooltip red_selection" title=" "> With so many pins available, we will read data from sensors, control different motors and actuators.</span><span id="n326" class="tooltip null_selection" title=" "> ? RC car: It will move in a specific direction and for a specific time based on the instructions from the computer, so that it can intercept the ball and prevent</span><span id="n327" class="tooltip null_selection" title=" "> goal. ? Goal Post: Some other physical things are required to complete the project like goal post.</span><span id="n328" class="tooltip null_selection" title=" "> ? Microsoft Visual Studio: To make a nice and simple user interface for most of the people. ? MatLab: It could be needed to do some more complex calculations.<br /><br /></span><span id="n329" class="tooltip red_selection" title=" "> ? Python: Python contain special libraries for machine learning namely scipy and numpy which great for linear algebra.</span><span id="n330" class="tooltip null_selection" title=" "> The language is great to use when working with machine learning algorithms and has easy syntax relatively. 1 5 D E S I G N S P E C I F I C A T I O N S 4 .</span><span id="n331" class="tooltip null_selection" title=" "> 1 S y s t e m A r c h i t e c t u r e F i g u r e 4 : S y s t e m A r c h i t e c t u r e 4 .</span><span id="n166" class="tooltip null_selection" title=" "> 2 D e s i g n L e v e l D i a g r a m s F i g u r e 5 : E R D i a g r a m 1 6 F i g u r e 6 : S e q u e n c e D i a g r a m F i g u r e 7 : C l a s s D i a g r a</span><span id="n225" class="tooltip null_selection" title=" "> m 1 7 F i g u r e 8 : S t a t e C h a r t D i a g r a m F i g u r e 9 : U s e C a s e # 1 1 8 F i g u r e 1 0 : U s e C a s e # 2 F i g u r e 1 1 : U s e C a s e</span><span id="n334" class="tooltip null_selection" title=" "> # 3 1 9 F i g u r e 1 2 : U M L C o m p o n e n t D i a g r a m F i g u r e 1 3 : C o n c e p t u a l A r c h i t e c t u r e o f t h e s y s t e m 2 0 F i g u r</span><span id="n335" class="tooltip null_selection" title=" "> e 1 4 : O b j e c t D e t e c t i o n A r c h i t e c t u r e F i g u r e 1 5 : A r c h i t e c t u r e o f M o v i n g B o t 2 1 F i g u r e 1 6 : C o n n e c t</span><span id="n336" class="tooltip null_selection" title=" "> i o n A r c h i t e c t u r e F i g u r e 1 7 : S y s t e m A r c h i t e c t u r e 2 2 4 .<br /><br /></span><span id="n337" class="tooltip null_selection" title=" "> 3 U s e r I n t e r f a c e D i a g r a m s F i g u r e 1 8 : U s e r I n t e r f a c e D i a g r a m 2 3 I M P L E M E N T A T I O N A N D E X P E R I M E N T A</span><span id="n338" class="tooltip red_selection" title=" "> L R E S U L T S 5 .</span><span id="n339" class="tooltip null_selection" title=" "> 1 E x p e r i m e n t a l S e t u p The final setup would be as follows:- ? A goal post of a length suitable to the dimensions of the room(3-5 Metres) ? The uniform</span><span id="n340" class="tooltip null_selection" title=" "> ground(color and surface) ? A remotely automated RC car that will behave as the goalkeeper ? Movement of the RC car will be restricted in 1-D only ? A green colored</span><span id="n341" class="tooltip null_selection" title=" "> ball with suitable dimensions(4-6 cm radius) ? An overhead camera to observe and detect the events ? An arduino combined with the RC car to receive instructions</span><span id="n342" class="tooltip null_selection" title=" "> from the computation program and to provide instructions to the RC car ? A machine learning program to detect the ball’s movement and predict the final landing point.<br /><br /></span><span id="n343" class="tooltip null_selection" title=" "> F i g u r e 1 9 : A S i m u l a t i o n m o d e l o f t h e E x p e r i m e n t a l s e t u p 2 4 5 . 2 E x p e r i m e n t a l A n a l y s i s 5.2.1</span><span id="n344" class="tooltip null_selection" title=" "> Data ? The Machine learning program can predict the ball’s movement with more than 95% accuracy and it can predict its centre with a whopping 100% accuracy.</span><span id="n345" class="tooltip null_selection" title=" "> ? The machine learning program can handle a frame rate of 30 or less ? The ball can have a maximum velocity of 0.7m/sec for accurate prediction.</span><span id="n346" class="tooltip null_selection" title=" "> However in some cases this velocity can be 2m/sec as well. ? The RC car can attain a maximum velocity of over 1.5m/sec. 5.2.2<br /><br /></span><span id="n347" class="tooltip null_selection" title=" "> Performance Parameters The software was executed in different environments before final accuracy was derived.</span><span id="n348" class="tooltip null_selection" title=" "> The software’s accuracy is 100% when background is of uniform color and surface and less than 70% when background is non uniform and lighting is non uniform.</span><span id="n349" class="tooltip null_selection" title=" "> Thus giving us an average accuracy of over 95%.</span><span id="n350" class="tooltip null_selection" title=" "> Ball’s of different colors were used before finally landing on the color green because of the advantage that the color does not interfere with the background.<br /><br /></span><span id="n351" class="tooltip null_selection" title=" "> More than 1000 test cases different starting coordinated were run to identify the suitable speed of the ball.</span><span id="n352" class="tooltip null_selection" title=" "> Different frame rates were chosen before landing on the suitable number 15 that balances accuracy and execution speed. 5 .</span><span id="n353" class="tooltip null_selection" title=" "> 3 W o r k i n g o f t h e p r o j e c t 5.3.1 Procedural Workflow F i g u r e 2 0 : P r o c e d u r a l W o r k f l o w D i a g r a m 2 5 5.3.2</span><span id="n354" class="tooltip null_selection" title=" "> Algorithmic Approaches Used The Viola-Jones Object Detection Framework is the first voice detection framework, which provides a real-time competitive object detection</span><span id="n355" class="tooltip red_selection" title=" "> rate, proposed in 2001 by Paul Viola and Michael Jones.<br /><br /></span><span id="n356" class="tooltip null_selection" title=" "> Although it can be trained to detect different types of object classes, it was mainly inspired by the problem of facial recognition.</span><span id="n357" class="tooltip null_selection" title=" "> F i g u r e 2 1 : E x a m p l e r e c t a n g l e f e a t u r e s s h o w n r e l a t i v e t o t h e e n c l o s i n g d e t e c t i o n w i n d o w The characteristics</span><span id="n358" class="tooltip red_selection" title=" "> of Viola–Jones algorithm which make it a good detection algorithm are: ? Robust – very high detection rate (true-positive rate) & very low false-positive rate always.</span><span id="n359" class="tooltip null_selection" title=" "> ? Real time – For practical applications at least 2 frames per second must be processed.<br /><br /></span><span id="n355" class="tooltip red_selection" title=" "> ? Face detection only (not recognition) - The goal is to distinguish faces from non-faces (detection is the first step in the recognition process).</span><span id="n361" class="tooltip red_selection" title=" "> The algorithm has four stages: (1)Haar Feature Selection (2)Creating an Integral Image (3)Adaboost Training (4)Cascading Classifiers Features sought by the detection</span><span id="n362" class="tooltip null_selection" title=" "> framework include the amount of image pixels within rectangular regions.</span><span id="n361" class="tooltip red_selection" title=" "> As such, they bear some resemblance to Haar basis functions, which have already been used in the realm of image-based object detection.<br /><br /></span><span id="n364" class="tooltip red_selection" title=" "> However, since the facilities used by Viola and Jones all rely on more than one rectangular area, they are 2 6 generally more complex.</span><span id="n365" class="tooltip null_selection" title=" "> The figure on the right shows the characteristics used in four different types of structures.</span><span id="n366" class="tooltip red_selection" title=" "> The value of any feature is the sum of pixels within explicit rectangles subtracted from the sum of pixels within the shaded rectangles.</span><span id="n367" class="tooltip red_selection" title=" "> This type of rectangular features are primitive when compared to alternatives such as steerable filters.<br /><br /></span><span id="n368" class="tooltip null_selection" title=" "> Although they are sensitive to vertical and horizontal characteristics, their response is quite coarse.</span><span id="n369" class="tooltip null_selection" title=" "> Using Viola-Jones for object tracking ? : In videos of moving objects, one does not need to apply object detection to each frame.</span><span id="n370" class="tooltip null_selection" title=" "> Instead, one can use tracking algorithms such as the KLT algorithm to detect the main features within the detection bounding box and track their movements between</span><span id="n371" class="tooltip null_selection" title=" "> frames.<br /><br /></span><span id="n372" class="tooltip null_selection" title=" "> This not only improves tracking speed by removing the need to re-locate objects in each frame, but it also improves robustness as well as more features than the</span><span id="n373" class="tooltip null_selection" title=" "> rotation and photometric changes from the main features Viola-Jones detection framework Is flexible.</span><span id="n374" class="tooltip null_selection" title=" "> Kanade–Lucas–Tomasi feature tracker ? : Kanade-Lucas - Tomasi (KLT) feature tracker is an approach to feature extraction.</span><span id="n375" class="tooltip null_selection" title=" "> It is proposed primarily to tackle this problem that traditional image registration techniques are generally expensive.<br /><br /></span><span id="n376" class="tooltip null_selection" title=" "> KLT uses spatial intensity information to direct location search that gives the best match.</span><span id="n377" class="tooltip null_selection" title=" "> This is faster than traditional techniques for investigating less potential matches between images. 5.3.3</span><span id="n378" class="tooltip null_selection" title=" "> Project Deployment The Following is the way the project is deployed: F i g u r e 2 2 : R o b o c a r w h i c h w i l l s t o p t h e b a l l 2 7 F i g u r e 2 3</span><span id="n379" class="tooltip null_selection" title=" "> : W i r e l e s s C a m e r a s y s t e m w i t h s t a n d F i g u r e 2 4 : B o t h b a l l a n d c a r a r e p l a c e d f o r t e s t i n g t o b e g i n 2 8</span><span id="n380" class="tooltip null_selection" title=" "> 5.3.4<br /><br /></span><span id="n379" class="tooltip null_selection" title=" "> System Screenshots F i g u r e 2 5 : S y s t e m s c r e e n s h o t o f O b j e c t d e t e c t i o n F i g u r e 2 6 : C o n s o l e S c r e e n s h o t o f t</span><span id="n166" class="tooltip null_selection" title=" "> h e o b j e c t ’ s i n s t a n t a n e o u s l o c a t i o n 2 9 F i g u r e 2 7 : S y s t e m s c r e e n s h o t o f a r d u i n o I D E 5 .</span><span id="n383" class="tooltip null_selection" title=" "> 4 T e s t i n g P r o c e s s 5.4.1 Test Plan The plan is to test for both normal and critical cases. That way we can measure the system’s limit in doing its task.</span><span id="n179" class="tooltip null_selection" title=" "> 5.4.1.1 Features to be tested • The system’s ability to successfully detect the presence of the ball in live camera feed.<br /><br /></span><span id="n385" class="tooltip null_selection" title=" "> • The system’s ability to accurately predict the future location of the ball. • The system’s ability to control the bot properly with commands.</span><span id="n386" class="tooltip null_selection" title=" "> • The goalkeeper bot’s ability to intercept the football before it hits the goal post.</span><span id="n387" class="tooltip null_selection" title=" "> • The camera-computer combination’s ability to track the ball’s position accurately and predict its route. • The bot’s high speed will be tested. 3 0 5.4.1.2</span><span id="n388" class="tooltip null_selection" title=" "> Test Strategy The strategy is to behave normally as any user would do while interacting with the system and give unconditioned input so that the system’s reliability</span><span id="n389" class="tooltip null_selection" title=" "> can be tested under random circumstances.<br /><br /></span><span id="n390" class="tooltip null_selection" title=" "> The Ball will be placed under the stand on which the camera is placed and car will be at some distance away straight from there.</span><span id="n391" class="tooltip null_selection" title=" "> Then the user is going to push the ball and system will do its work to stop the ball. 5.4.1.3</span><span id="n392" class="tooltip null_selection" title=" "> Test Techniques The Ball can be pushed slowly or fast-ly or at a moderate speed. The car needs to validate itself in both left and right directions.</span><span id="n393" class="tooltip null_selection" title=" "> The ball’s movement will be tested through the frame of live video stream coming from wireless camera which is sometimes unreliable due to latency to broadcast or</span><span id="n394" class="tooltip null_selection" title=" "> frame stuttering. 5.4.2<br /><br /></span><span id="n395" class="tooltip null_selection" title=" "> Test Cases F i g u r e 2 8 : C a r i s s t a t i o n a r y a s t h e b a l l h a s n o t m o v e d 3 1 F i g u r e 2 9 : T h e b a l l a n d c a r b o t h m o v</span><span id="n396" class="tooltip null_selection" title=" "> e F i g u r e 3 0 : C a r s u c c e s s f u l l y c a t c h e s t h e b a l l 3 2 5.4.3</span><span id="n397" class="tooltip null_selection" title=" "> Test Results In all the test cases shown above the car and the system passed the test and it is working. 5 .</span><span id="n398" class="tooltip null_selection" title=" "> 5 R e s u l t s a n d D i s c u s s i o n s Following results can be observed: i.<br /><br /></span><span id="n399" class="tooltip null_selection" title=" "> Using a local camera gives a 95% accuracy while using a remove camera wirelessly transferring frames via Bluetooth or Wifi gives 92% accuracy ii.</span><span id="n400" class="tooltip null_selection" title=" "> Using a local camera allows the program to have a frame rate less than or equal to 30 while using a remote camera shifts the frame rate to a mere 15. iii.</span><span id="n401" class="tooltip null_selection" title=" "> A 12 MP camera is the optimal choice since it establishes an optimal balance between accuracy, quality of frame and computational time iv.</span><span id="n402" class="tooltip null_selection" title=" "> The program can successfully detect the moving object trace its centre and predict its final landing point under 0.2 sec of response time.<br /><br /></span><span id="n403" class="tooltip null_selection" title=" "> And remote camera can transfer high quality feed with a successfully frame rate of 15 under 0.1sec (estimate). 5 .</span><span id="n404" class="tooltip null_selection" title=" "> 6 I n f e r e n c e s D r a w n Semantic segmentation is a long-studied problem in computer vision and is one of the grand challenges to solve when it comes to automatically</span><span id="n405" class="tooltip null_selection" title=" "> understanding the world we live in. Essentially, semantic segmentation allows us to assign a hierarchical tag (also called a label). Each pixel in an image.</span><span id="n406" class="tooltip null_selection" title=" "> This is relatively easy for humans, as we can usually understand the content of an image in terms of the objects it contains.<br /><br /></span><span id="n407" class="tooltip null_selection" title=" "> For example, most of us can identify cars, pedestrians, houses etc. and are not meant to think twice about it.</span><span id="n408" class="tooltip null_selection" title=" "> However, teaching machines to see (and, moreover, understand) what is happening in an image for a completely different story.</span><span id="n409" class="tooltip null_selection" title=" "> These days, we take it for granted that 10 megapixels say an image will have a resolution, which means a machine essentially has 2 million points to settle on a</span><span id="n410" class="tooltip null_selection" title=" "> 2 million grid. But how can we help orient ourselves computer to such a vast pool of data and actually provide us with meaning annotations for each pixel in an image.<br /><br /></span><span id="n411" class="tooltip null_selection" title=" "> 3 3 5 . 7 V a l i d a t i o n o f O b j e c t i v e s T A B L E 6 : V a l i d a t i o n o f O b j e c t i v e s S . N o .</span><span id="n412" class="tooltip null_selection" title=" "> O b j e c t i v e s S t a t u s 1 T h e s y s t e m w i l l b e a b l e t o s u c c e s s f u l l y d e t e c t t h e p r e s e n c e o f t h e b a l l i n l i v</span><span id="n413" class="tooltip null_selection" title=" "> e c a m e r a f e e d .</span><span id="n226" class="tooltip null_selection" title=" "> S u c c e s s f u l 2 T h e s y s t e m s h o u l d b e a b l e t o a c c u r a t e l y p r e d i c t t h e f u t u r e l o c a t i o n o f t h e b a l l .<br /><br /></span><span id="n415" class="tooltip null_selection" title=" "> S u c c e s s f u l 3 T h e s y s t e m s h o u l d b e a b l e t o c o n t r o l t h e b o t p r o p e r l y w i t h c o m m a n d s S u c c e s s f u l 4 T h e</span><span id="n416" class="tooltip null_selection" title=" "> g o a l k e e p e r b o t s h a l l b e a b l e t o i n t e r c e p t t h e f o o t b a l l b e f o r e i t h i t s t h e g o a l p o s t S u c c e s s f u l 5 T</span><span id="n166" class="tooltip null_selection" title=" "> h e c a m e r a - c o m p u t e r c o m b i n a t i o n w i l l b e a b l e t o t r a c k t h e b a l l ’ s p o s i t i o n a c c u r a t e l y a n d p r e d i c</span><span id="n337" class="tooltip null_selection" title=" "> t i t s r o u t e . S u c c e s s f u l 6 T h e b o t w i l l h a v e h i g h s p e e d m o t o r t o e n s u r e q u i c k m o v e m e n t .<br /><br /></span><span id="n419" class="tooltip null_selection" title=" "> S u c c e s s f u l 3 4 C O N C L U S I O N S A N D F U T U R E D I R E C T I O N S 6 .</span><span id="n420" class="tooltip null_selection" title=" "> 1 C o n c l u s i o n s The final project included a camera module optimised to a frame rate that will be transferred to the computer immediately and a machine learning</span><span id="n421" class="tooltip null_selection" title=" "> algorithm drafted in Python 3 that will take in frame recorded from the camera and will determine its locations and angle, speed with respect to the previous location.</span><span id="n160" class="tooltip null_selection" title=" "> The angle and speed calculated will be stored in a database that will be used to predict the final landing point of the ball.<br /><br /></span><span id="n423" class="tooltip null_selection" title=" "> The Python program will trigger the Arduino program that will calculate the distance, speed and direction of the bot required to stop the ball from hitting the target.</span><span id="n162" class="tooltip null_selection" title=" "> The instructions will be transferred to the bot via a zigbee and the bot will execute the instructions with the help of an Arduino attached to it.The</span><span id="n425" class="tooltip null_selection" title=" "> bot will be made by reverse engineering a wireless remote controlled car or will be designed from scratch with a high speed motor at the very base. 6 .</span><span id="n426" class="tooltip null_selection" title=" "> 2 E n v i r o n m e n t a l , E c o n o m i c a n d S o c i e t a l B e n e f i t s The project will benefit the society in a very positive manner, athletes can</span><span id="n427" class="tooltip null_selection" title=" "> train on this bot for goalshoot practicing. Children can play with it indoors without need of a companion.<br /><br /></span><span id="n428" class="tooltip null_selection" title=" "> It can be developed in 3d to train cricketers -- batsmen -- to a level that wasn't thought of before. There are hundreds ,if not a thousand, benefits of this project.</span><span id="n429" class="tooltip null_selection" title=" "> It can be used wherever an autonomous target interception has to be used. 6 .</span><span id="n430" class="tooltip null_selection" title=" "> 3 R e f l e c t i o n s The target of developing an autonomous bot has been achieved with a camera module that sends live footage to the computer which in turn processes</span><span id="n431" class="tooltip null_selection" title=" "> the footage frame by frame and trains the ML algo using it. The algo in turn predicts the landing point and instructs the bot to intercept it.<br /><br /></span><span id="n432" class="tooltip null_selection" title=" "> In General, the project can be defined as an autonomous high speed target interceptor in real time. 6 .</span><span id="n433" class="tooltip null_selection" title=" "> 4 F u t u r e W o r k This technique can be further developed to manufacture a missile interceptor for Indian Defense.</span><span id="n434" class="tooltip null_selection" title=" "> A weapon that no country posses, not even USA. This weapon can give any country massive advantage over its enemies.</span><span id="n435" class="tooltip null_selection" title=" "> Anti- missile weapon is the ultimate protection any country can hope for.<br /><br /></span><span id="n256" class="tooltip null_selection" title=" "> The techniques involved in autonomous goalkeeper are very similar to techniques that will one be used to develop the ultimate anti missile project.</span><span id="n437" class="tooltip red_selection" title=" "> 3 5 P R O J E C T M E T R I C S 7 .</span><span id="n438" class="tooltip null_selection" title=" "> 1 C h a l l e n g e s F a c e d ? Keeping Team on The Same Page ? Poorly Defining the Goals And Objectives ? Unrealistic Deadlines ? Insufficient Team Skills ? Miscommunication</span><span id="n439" class="tooltip red_selection" title=" "> Causing Conflicts ? Risk Management ? Challenges of Teamwork ? Lack of Accountability 7 .<br /><br /></span><span id="n440" class="tooltip null_selection" title=" "> 2 R e l e v a n t S u b j e c t s Relevant Subjects related to the project: Artificial intelligence ? : Areas of artificial intelligence for robotic systems to navigate</span><span id="n441" class="tooltip red_selection" title=" "> through the environment deal with autonomous planning or deliberation. A detailed understanding of these environments is necessary to navigate through these mediums.</span><span id="n442" class="tooltip red_selection" title=" "> Information about the environment can be provided by a computer vision system, acting as a vision sensor and providing high-level information about the environment</span><span id="n443" class="tooltip red_selection" title=" "> and robots. Artificial intelligence and computer vision share other disciplines such as pattern recognition and learning techniques.<br /><br /></span><span id="n444" class="tooltip null_selection" title=" "> As a result, computer vision is sometimes viewed as a part of the field of artificial intelligence or, in general, the computer science field.</span><span id="n445" class="tooltip red_selection" title=" "> Solid-state physics ? : Solid-state physics is another field closely related to computer vision.</span><span id="n446" class="tooltip red_selection" title=" "> Most computer vision systems rely on image sensors that detect electromagnetic radiation, usually in the form of visible or infra-red light.</span><span id="n447" class="tooltip red_selection" title=" "> The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics.<br /><br /></span><span id="n448" class="tooltip null_selection" title=" "> Physics explains the behavior of optics which is a core part of most imaging systems.</span><span id="n447" class="tooltip red_selection" title=" "> Sophisticated image sensors also require quantum mechanics to provide a complete understanding of the image formation process.</span><span id="n450" class="tooltip null_selection" title=" "> In addition, various measurement problems in physics can be addressed using computer vision, for example motion in liquids.</span><span id="n451" class="tooltip null_selection" title=" "> Neurobiology ? : A third area that plays an important role is neurobiology, specifically the study of biological vision systems.<br /><br /></span><span id="n452" class="tooltip red_selection" title=" "> Over the last century, a comprehensive study of eyes, neurons, and brain structures devoted to the processing of visual stimuli has been performed in both humans</span><span id="n453" class="tooltip null_selection" title=" "> and various animals. It turns out to be a rough, yet complex, description of how a "real" vision system operates to solve certain vision functions.</span><span id="n447" class="tooltip red_selection" title=" "> These results have led 3 6 to a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems</span><span id="n455" class="tooltip red_selection" title=" "> at different levels of complexity.<br /><br /></span><span id="n456" class="tooltip null_selection" title=" "> Also, he has a background in biology for some of the methods of learning developed within computer vision (such as neural nets and deep learning based on image and</span><span id="n457" class="tooltip red_selection" title=" "> feature analysis and classification).</span><span id="n458" class="tooltip red_selection" title=" "> Some varieties of computer vision research are closely related to the study of biological vision - in fact, many varieties of AI research are closely associated</span><span id="n459" class="tooltip null_selection" title=" "> with research in human consciousness, and stored knowledge to interpret, integrate, and use visual information. use of.<br /><br /></span><span id="n460" class="tooltip null_selection" title=" "> Biological vision models the physiological processes behind the field of study and visual perception in humans and other animals.</span><span id="n461" class="tooltip red_selection" title=" "> Computer vision, on the other hand, studies and describes the processes applied in software and hardware behind artificial vision systems.</span><span id="n445" class="tooltip red_selection" title=" "> Interdisciplinary exchange between biological and computer vision has proved fruitful for both fields.</span><span id="n463" class="tooltip null_selection" title=" "> Signal processing ? : Yet another area related to computer vision is signal processing.<br /><br /></span><span id="n446" class="tooltip red_selection" title=" "> Several methods for processing one-variable signals, typically temporal signals, can be extended to computer vision for processing two-variable signals or multi-variable</span><span id="n465" class="tooltip null_selection" title=" "> signals from a natural point of view.</span><span id="n466" class="tooltip red_selection" title=" "> However, due to the specific nature of the images, several methods have evolved within computer vision, with no counterpart in the processing of one-variable signals.</span><span id="n445" class="tooltip red_selection" title=" "> Along with the multi-dimensionality of the signal, it defines a subfield in signal processing as a part of computer vision.<br /><br /></span><span id="n468" class="tooltip red_selection" title=" "> Other fields ? : Apart from the above mentioned views on computer vision, many of the related research topics can also be studied from a purely mathematical point</span><span id="n469" class="tooltip null_selection" title=" "> of view. For example, many methods in computer vision are based on statistics, optimization, or geometry.</span><span id="n468" class="tooltip red_selection" title=" "> Finally, an important part of the field is devoted to the implementation aspect of computer vision; How existing methods can be realized in various combinations</span><span id="n471" class="tooltip null_selection" title=" "> of software and hardware, or how these methods can be modified to achieve processing speed without losing too much performance.<br /><br /></span><span id="n472" class="tooltip null_selection" title=" "> Computer vision is also used in the fashion ecommerce, inventory management, patent search, furniture and beauty industries. 7 .</span><span id="n473" class="tooltip null_selection" title=" "> 3 I n t e r d i s c i p l i n a r y K n o w l e d g e S h a r i n g The ultimate goal of computer vision is to make possible systems that can autonomously interpret</span><span id="n474" class="tooltip null_selection" title=" "> the visual environment under almost any operating condition. That is, to reproduce the amazing performance of the human visual perception.</span><span id="n475" class="tooltip null_selection" title=" "> The elusiveness of this goal can be seen from attempting to define robustness in the context of computer based image understanding.<br /><br /></span><span id="n476" class="tooltip null_selection" title=" "> Different definitions emerge at different levels of the hierarchy of techniques often associated with solutions to computer vision problems.</span><span id="n477" class="tooltip null_selection" title=" "> On the top level, a robust vision system should be able to recognize new objects based exclusively on previous 3 7 examples from the same class of functionality.</span><span id="n478" class="tooltip null_selection" title=" "> Thus, a piece of furniture should be identified independent of its style, a car independent of its maker, etc.</span><span id="n479" class="tooltip null_selection" title=" "> Such cognitive components however are yet to be developed for general purpose vision systems.<br /><br /></span><span id="n480" class="tooltip red_selection" title=" "> Changes in the visual environment due to nonrigid motion of the objects or alteration of viewpoint, or both, are a primary concern when building object descriptions</span><span id="n481" class="tooltip null_selection" title=" "> at the intermediate level of the vision hierarchy.</span><span id="n480" class="tooltip red_selection" title=" "> Complex visual events arise for which robust interpretation requires separating the external causes from the intrinsic properties in the appearance of each object.</span><span id="n480" class="tooltip red_selection" title=" "> This task, roughly equivalent to perceptual constancies in human visual perception, is currently an active research area in computer vision. 7 .<br /><br /></span><span id="n484" class="tooltip null_selection" title=" "> 4 P e e r A s s e s s m e n t M a t r i x The following is a Matrix on 1 (min) to 5 (max) rating of contribution of group members by each member.</span><span id="n485" class="tooltip null_selection" title=" "> T A B L E 4 : P e e r A s s e s s m e n t M a t r i x Evaluation Of: Taranjeet Singh Vaibhav Sood Utkarsh Chugh Tushar Mahajan Evaluated Taranjeet Singh 5 5 5 5</span><span id="n486" class="tooltip null_selection" title=" "> By: Vaibhav Sood 5 5 5 5 Utkarsh Chugh 5 5 5 5 Tushar Mahajan 5 5 5 5 7 .</span><span id="n487" class="tooltip null_selection" title=" "> 5 R o l e P l a y i n g a n d W o r k S c h e d u l e Team members played different roles at different times according to the need, members also usually shifted</span><span id="n488" class="tooltip null_selection" title=" "> from their role to the others if for some reason the other wasn’t able to do their work.<br /><br /></span><span id="n489" class="tooltip null_selection" title=" "> Members usually worked during day however they also worked on night time some days. 3 8 7 .</span><span id="n490" class="tooltip null_selection" title=" "> 6 S t u d e n t O u t c o m e s D e s c r i p t i o n a n d P e r f o r m a n c e I n d i c a t o r s T A B L E 5 : S O & P I ( A - K M a p p i n g ) SO Description</span><span id="n491" class="tooltip null_selection" title=" "> Outcome A1 Applying mathematical concepts to obtain analytical and numerical solutions.</span><span id="n492" class="tooltip null_selection" title=" "> Used mathematical concepts like Trigonometry for accurate direction predicting in image processing. These concepts were also used to calculate the results..<br /><br /></span><span id="n493" class="tooltip null_selection" title=" "> A2 Applying basic principles of science towards solving engineering problems Applied basic principles of physics like speed, momentum and acceleration.</span><span id="n494" class="tooltip null_selection" title=" "> A3 Applying engineering techniques for solving computing problems Chose a fast kind of remotely controlled car for high catch rates.</span><span id="n495" class="tooltip null_selection" title=" "> B1 Identify the constraints, assumptions and models for the problems.</span><span id="n496" class="tooltip null_selection" title=" "> Understood the physical and computational limits to the project B2 Use appropriate methods, tools and techniques for data collection.<br /><br /></span><span id="n497" class="tooltip null_selection" title=" "> used emerging technologies like Computer vision, ML for the solution B3 Analyze and interpret results with respect to assumptions, constraints and theory.</span><span id="n498" class="tooltip null_selection" title=" "> Analyzed the results which seem to follow the established constraints and assumptions. C1 Design software system to address desired needs in different problem domains.</span><span id="n499" class="tooltip null_selection" title=" "> wrote appropriate Arduino and python scripts C2 Can understand scope and constraints such as economic, environmental, social, political, ethical, health and safety,</span><span id="n500" class="tooltip null_selection" title=" "> manufacturability, and sustainability.<br /><br /></span><span id="n501" class="tooltip null_selection" title=" "> the scope of this project is well beyond traditional limits, it has high economic, environmental and safety potential D1 Fulfill assigned responsibility in multidisciplinary</span><span id="n502" class="tooltip null_selection" title=" "> teams. Fulfilled the assigned responsibility D2 Can play different roles as a team player.</span><span id="n503" class="tooltip red_selection" title=" "> Members played several different roles at different times E1 Identify engineering problems.</span><span id="n504" class="tooltip null_selection" title=" "> identified the engineering 3 9 problems while making the architecture of the system E2 Develop appropriate models to formulate solutions.<br /><br /></span><span id="n505" class="tooltip null_selection" title=" "> Appropriate architecture models were formulated to find solutions E3 Use analytical and computational methods to obtain solutions.</span><span id="n506" class="tooltip null_selection" title=" "> Used basic trigonometry to solve the prediction problem F1 Showcase professional responsibility while interacting with peers and professional communities Gave well</span><span id="n507" class="tooltip null_selection" title=" "> and good presentation to the capstone panel and were professional with mentor F2 Able to evaluate the ethical dimensions of a problem.</span><span id="n508" class="tooltip null_selection" title=" "> Understand that this technology can be used as both offensive and defensive G1 Produce a variety of documents such as laboratory or project reports using appropriate</span><span id="n509" class="tooltip null_selection" title=" "> formats. Used the official formats for reports G2 Deliver well-organized and effective oral presentation.<br /><br /></span><span id="n510" class="tooltip null_selection" title=" "> A well understood presentation was given to the panel H1 Aware of environmental and societal impact of engineering solutions.</span><span id="n511" class="tooltip null_selection" title=" "> Engineering solutions can have great and good impact on environment H2 Examine economic tradeoffs in computing systems.</span><span id="n512" class="tooltip null_selection" title=" "> Everything has a price so does electronics and computers I1 Able to explore and utilize resources to enhance self-learning.</span><span id="n513" class="tooltip null_selection" title=" "> Explored different resources like library, internet, etc for self learning I2 Recognize the importance of life-long learning.<br /><br /></span><span id="n514" class="tooltip null_selection" title=" "> any skills learned can be useful in future life J1 Comprehend the importance of contemporary issues.</span><span id="n515" class="tooltip null_selection" title=" "> We live in a society, it has specific sociological structure and it has to stay stable or our lives are at stake K1 Write code in different programming languages.</span><span id="n516" class="tooltip null_selection" title=" "> Written code in python and arduino IDE K2 Apply different data structures and algorithmic Different data structures were 4 0 techniques.</span><span id="n517" class="tooltip null_selection" title=" "> used for various operations K3 Use software tools necessary for computer engineering domain used software such as jupyter, spyder, visual studio, arduino uno, etc.<br /><br /></span><span id="n518" class="tooltip null_selection" title=" "> 7 . 7 B r i e f A n a l y t i c a l A s s e s s m e n t Q1.</span><span id="n519" class="tooltip null_selection" title=" "> What sources of information did your team explored to arrive at the list of possible Project Problems? Ans: ? Our team explored sources including but not limited</span><span id="n520" class="tooltip null_selection" title=" "> to library, internet, mentors, professors, etc. Q2.</span><span id="n521" class="tooltip null_selection" title=" "> What analytical, computational and/or experimental methods did your project team use to obtain solutions to the problems in the project? Ans: ? Our team used team</span><span id="n522" class="tooltip null_selection" title=" "> used KLT Feature tracker algorithm to compute feature extraction of the moving ball. Q3.<br /><br /></span><span id="n523" class="tooltip null_selection" title=" "> Did the project demand demonstration of knowledge of fundamentals, scientific and/or engineering principles? If yes, how did you apply? Ans: ? Yes the project demanded</span><span id="n524" class="tooltip null_selection" title=" "> demonstration of knowledge of fundamentals, scientific principles. We consulted our professors for the help. Q4.</span><span id="n525" class="tooltip null_selection" title=" "> How did your team shares responsibility and communicate the information of schedule with others in team to coordinate design and manufacturing dependencies? Ans:</span><span id="n526" class="tooltip null_selection" title=" "> ? Our team shared responsibilities and communicated the information of schedule with others in team using whatsapp, mobile calling, in person meetings, etc. Q5.<br /><br /></span><span id="n527" class="tooltip null_selection" title=" "> What resources did you use to learn new materials not taught in class for the course of the project? Ans: ? Our team used resources like internet, library, mentors</span><span id="n528" class="tooltip null_selection" title=" "> to learn new materials and technologies. Q6.</span><span id="n529" class="tooltip null_selection" title=" "> Does the project make you appreciate the need to solve problems in real life using engineering and could the project development make you proficient with software</span><span id="n530" class="tooltip null_selection" title=" "> development tools and environments? Ans: ? Yes the project made us appreciate the need to solve problems in real life using engineering and the project made us proficient</span><span id="n531" class="tooltip null_selection" title=" "> with Software development as a whole. 4 1 A P P E N D I X A : R E F E R E N C E S [1] T. Anderson, L. Peterson, S. Shenker, J. Turner.<br /><br /></span><span id="n532" class="tooltip null_selection" title=" "> “Overcoming the Internet impasse through virtualization.” ? IEEE Computer ? , vol. 38(4), pp. 34-41, Jan. 26, 2005. [2] M. Duncan.</span><span id="n533" class="tooltip null_selection" title=" "> (Author(s)) “Engineering Concepts on Ice.” (Website Name) Internet: www.iceengg.edu/staff.html (Website URL), Oct. 25, 2000 (Date website updated or published) [Nov.</span><span id="n534" class="tooltip null_selection" title=" "> 29, 2003 (date you last accessed the website)].</span><span id="n535" class="tooltip null_selection" title=" "> [3] Zeid Al-Husseiny ? , ? Filiph ? ? Appelgren ? , ? Jeton ? ? Mustini (Author(s)), “Robot Goalkeeper” [4] Agin, G.J.,<br /><br /></span><span id="n536" class="tooltip red_selection" title=" "> "Real Time Control of a Robot with a Mobile Camera". Technical Note 179, SRI International, Feb. 1979.</span><span id="n537" class="tooltip red_selection" title=" "> [5] "High-speed Catching System (exhibited at the National Museum of Emerging Science and Innovation since 2005)". Ishikawa Watanabe Laboratory, University of Tokyo.</span><span id="n538" class="tooltip red_selection" title=" "> Retrieved 12 February 2015. [6] F. Chaumette, S. Hutchinson. ? Visual Servo Control, Part I: Basic Approaches.</span><span id="n539" class="tooltip null_selection" title=" "> ? IEEE Robotics and Automation Magazine, 13(4):82-90, December 2006 [7] A. C. Sanderson and L. E. Weiss. Adaptive visual servo control of robots. In A.<br /><br /></span><span id="n540" class="tooltip null_selection" title=" "> Pugh, editor, Robot Vision, pages 107–116.</span><span id="n541" class="tooltip null_selection" title=" "> IFS, 1983 4 2 A P P E N D I X B : P L A G I A R I S M R E P O R T 4 3</span>
<span id="class#" class="tooltip red_selection" title="tooltip#">  </span>
<!--Content_End-->

<!--Body_Start-->
</p>
</div>
</div>
<div class="upload-content content_info">
<div class="command-rcol">
<div class="title_right_col">Sources found:</div>
<div class="italic_hint_txt sources_hint">Click on the highlighted sentence to see sources.</div>
<ul class="list_link">
<h3 style="display: none;">Internet Pages</h3>
<!--Body_End-->

<li class="n0"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://d3giikteahxfyn.cloudfront.net/1a0ec61f-6a1d-41cf-97a8-31331bce9c40/293e7d2b-e0c5-4084-bcd8-9e5cd6766442>https://d3giikteahxfyn.cloudfront.net/1a</a></li><li class="n2"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://aphrdi.ap.gov.in/uploads/25677-Profile%20of%20Dr%20M.A.%20Saleem.pdf>https://aphrdi.ap.gov.in/uploads/25677-P</a></li><li class="n4"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.ncte.org/library/NCTEFiles/Resources/Journals/CCC/0612-dec09/CCC0612Teaching.pdf>http://www.ncte.org/library/NCTEFiles/Re</a></li><li class="n13"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px>1%</span> <a class="show_texts" href=https://towardsdatascience.com/recent-advances-in-modern-computer-vision-56801edab980>https://towardsdatascience.com/recent-ad</a></li><li class="n14"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.hindawi.com/journals/mpe/2015/931256/>https://www.hindawi.com/journals/mpe/201</a></li><li class="n15"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px>1%</span> <a class="show_texts" href=https://create.arduino.cc/projecthub/crakers/where-s-my-stuff-find-your-misplaced-things-with-alexa-d354e9>https://create.arduino.cc/projecthub/cra</a></li><li class="n21"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://issuu.com/signemagazine/docs/signe_edition_1>https://issuu.com/signemagazine/docs/sig</a></li><li class="n22"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.punjabiuniversity.ac.in/Pages/Images/IQAC/SSR_PunjabiUniversityPatiala_PartI_MSP-2.9.15-final.pdf>http://www.punjabiuniversity.ac.in/Pages</a></li><li class="n25"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://scholar.google.co.in/citations?user=F14FHsIAAAAJ>http://scholar.google.co.in/citations?us</a></li><li class="n28"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.globalinstitutes.edu.in/gimet/gimet-mca/>https://www.globalinstitutes.edu.in/gime</a></li><li class="n30"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://erepository.uonbi.ac.ke/bitstream/handle/11295/13416/Onsongo_Strategies%20Adopted%20By%20Non%20Governmental%20Organizations%20To%20Achieve%20Financial%20Sustainability%20In%20Kenya.pdf?sequence=1>http://erepository.uonbi.ac.ke/bitstream</a></li><li class="n35"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://eprints.utar.edu.my/1193/1/IA-2014-1002742-1.pdf>http://eprints.utar.edu.my/1193/1/IA-201</a></li><li class="n41"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.who.int/ageing/projects/elder_abuse/alc_ea_ken.pdf>https://www.who.int/ageing/projects/elde</a></li><li class="n43"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://idpf.org/epub/do/>http://idpf.org/epub/do/</a></li><li class="n44"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.se.rit.edu/~foryourhealth/srs.pdf>http://www.se.rit.edu/~foryourhealth/srs</a></li><li class="n45"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.microsemi.com/document-portal/doc_download/133620-dg0534-interfacing-igloo2-fpga-with-external-lpddr-memory-through-mddr-controller-libero-soc-v11-8-sp2-demo-guide>https://www.microsemi.com/document-porta</a></li><li class="n49"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.coursehero.com/file/19636793/Textbook/>https://www.coursehero.com/file/19636793</a></li><li class="n55"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://cordis.europa.eu/docs/projects/cnect/9/287119/080/deliverables/001-D33TestStrategyandTestCases.pdf>https://cordis.europa.eu/docs/projects/c</a></li><li class="n58"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://ehp.niehs.nih.gov/doi/full/10.1289/EHP3534>https://ehp.niehs.nih.gov/doi/full/10.12</a></li><li class="n62"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.xilinx.com/support/documentation/boards_and_kits/vcu128/ug1302-vcu128-eval-bd.pdf>https://www.xilinx.com/support/documenta</a></li><li class="n64"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://s21.q4cdn.com/589145389/files/doc_documents/EN/2017/12/A150-14-R2261-Hazardous-Material-Management-Plan_EN.pdf>https://s21.q4cdn.com/589145389/files/do</a></li><li class="n66"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://course.ccs.neu.edu/com3205/sampleproject.doc>https://course.ccs.neu.edu/com3205/sampl</a></li><li class="n75"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://everythingatoneclick.blogspot.com/2010_12_01_archive.html>https://everythingatoneclick.blogspot.co</a></li><li class="n77"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://habitech.s3.amazonaws.com/PDFs/YAM/MusicCast/Yamaha%20MusicCast%20HTTP%20simplified%20API%20for%20ControlSystems.pdf>http://habitech.s3.amazonaws.com/PDFs/YA</a></li><li class="n78"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.prestige-sales.com/pdf/presto-lifts-product-overveiw.pdf>http://www.prestige-sales.com/pdf/presto</a></li><li class="n92"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://developer.apple.com/videos/play/wwdc2018/716/>https://developer.apple.com/videos/play/</a></li><li class="n93"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://ehsangazar.com/object-tracking-with-opencv-fd18ccdd7369>https://ehsangazar.com/object-tracking-w</a></li><li class="n96"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px>1%</span> <a class="show_texts" href=https://www.creoqode.com/nova-education-ch13>https://www.creoqode.com/nova-education-</a></li><li class="n97"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://forum.unity.com/threads/find-out-real-position-of-a-child-gameobject.73658/>https://forum.unity.com/threads/find-out</a></li><li class="n101"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.tenniselbowsecretsrevealed.com/12-elbow-injuries-that-can-make-everyday-life-a-living-hell/>https://www.tenniselbowsecretsrevealed.c</a></li><li class="n105"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.geeksforgeeks.org/type-isinstance-python/>https://www.geeksforgeeks.org/type-isins</a></li><li class="n109"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.slideshare.net/yuhuang/visual-object-detection-recognition-tracking-without-deep-learning>https://www.slideshare.net/yuhuang/visua</a></li><li class="n112"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://code-examples.net/en/q/da6e60>https://code-examples.net/en/q/da6e60</a></li><li class="n114"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://blog.csdn.net/yuyangyg/article/details/79641214>https://blog.csdn.net/yuyangyg/article/d</a></li><li class="n116"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://neider.intimategadgets.info/thesis-proposal/video-object-tracking-thesis.html>https://neider.intimategadgets.info/thes</a></li><li class="n118"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.pyimagesearch.com/2018/08/06/tracking-multiple-objects-with-opencv/>https://www.pyimagesearch.com/2018/08/06</a></li><li class="n120"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://arxiv.org/pdf/1708.02709>https://arxiv.org/pdf/1708.02709</a></li><li class="n126"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.quickgs.com/list-of-indian-missiles-with-range/>http://www.quickgs.com/list-of-indian-mi</a></li><li class="n131"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.cnet.com/forums/discussions/videoing-soccer-games/>https://www.cnet.com/forums/discussions/</a></li><li class="n135"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://stallman.org/archives/2017-may-aug.html>https://stallman.org/archives/2017-may-a</a></li><li class="n137"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://blog.floydhub.com/toy-self-driving-car-part-one/>https://blog.floydhub.com/toy-self-drivi</a></li><li class="n138"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://forums.anandtech.com/threads/how-many-9s-between-1-100.311319/>https://forums.anandtech.com/threads/how</a></li><li class="n140"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.pinterest.com/pin/416723771768101709/>https://www.pinterest.com/pin/4167237717</a></li><li class="n143"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.essaysharkwriters.com/blog/how-do-jem-and-scout-change-during-the-course-of-the-novel-how-do-they-remain-the-same/>https://www.essaysharkwriters.com/blog/h</a></li><li class="n147"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.pymnts.com/wp-content/uploads/2019/03/AI-GAP-STUDY-November-2018.pdf>https://www.pymnts.com/wp-content/upload</a></li><li class="n149"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.pymnts.com/artificial-intelligence-study/>https://www.pymnts.com/artificial-intell</a></li><li class="n151"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://issuu.com/eshabiba/docs/t22-10-2015_844a2bdc3ad05f>https://issuu.com/eshabiba/docs/t22-10-2</a></li><li class="n154"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://ftp.itam.mx/pub/alfredo/PAPERS/Weitzenfeld10691.pdf>http://ftp.itam.mx/pub/alfredo/PAPERS/We</a></li><li class="n157"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://ftp.itam.mx/pub/investigadores/alfredo/PAPERS/Weitzenfeld10691.pdf>http://ftp.itam.mx/pub/investigadores/al</a></li><li class="n160"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://medium.com/@ha_san_ali/machine-learning-with-tensorflow-for-the-average-joe-a3a220095678>https://medium.com/@ha_san_ali/machine-l</a></li><li class="n162"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.projectsof8051.com/mobile-controlled-robot/>https://www.projectsof8051.com/mobile-co</a></li><li class="n164"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/26-1/advanced26-1.pdf>https://www.fq.math.ca/Scanned/26-1/adva</a></li><li class="n165"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://files.constantcontact.com/fcb8d87d301/7fcf251c-b04e-4c7f-a80d-06f2c8f89fe4.pdf>http://files.constantcontact.com/fcb8d87</a></li><li class="n166"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/26-2/advanced26-2.pdf>https://www.fq.math.ca/Scanned/26-2/adva</a></li><li class="n167"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://d2xcq4qphg1ge9.cloudfront.net/assets/19/3691253/original_PABST_20BLUE_20RIBBON_20_E2_80_9CEASY_20VINTAGE_E2_80_9D_20SWEEPSTAKES.pdf>https://d2xcq4qphg1ge9.cloudfront.net/as</a></li><li class="n170"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/google_US2016election_findings_1_zm64A1G.pdf>https://storage.googleapis.com/gweb-unib</a></li><li class="n171"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://s3.amazonaws.com/perscholas/about/NON-DISCRIMINATIONPOLICY.pdf>https://s3.amazonaws.com/perscholas/abou</a></li><li class="n172"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://abc.xyz/investor/static/pdf/2017_Q4_Earnings_Transcript.pdf>https://abc.xyz/investor/static/pdf/2017</a></li><li class="n175"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/24-4/horadam1.pdf>https://www.fq.math.ca/Scanned/24-4/hora</a></li><li class="n178"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.tetoncountyidaho.gov/use_images/pdf/forms/fy2020budget.pdf>https://www.tetoncountyidaho.gov/use_ima</a></li><li class="n179"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/>https://www.pyimagesearch.com/2015/09/14</a></li><li class="n180"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.softpanorama.org/Windows/index.shtml>http://www.softpanorama.org/Windows/inde</a></li><li class="n181"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.sciencebuddies.org/science-fair-projects/project-ideas/Phys_p089/physics/physics-of-catapult-projectile-motion>https://www.sciencebuddies.org/science-f</a></li><li class="n188"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.albany.edu/facilities/alerts/Downtown_Campus_Annual_Flush_of_Stand_Pipes_in_Hawley_Milne_Page_and_Richardson_01_07_20.pdf>https://www.albany.edu/facilities/alerts</a></li><li class="n190"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://espacioaudiovisualelmerzambrano.blogspot.com/>https://espacioaudiovisualelmerzambrano.</a></li><li class="n192"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://issuu.com/land-magazines/docs/l19_3>https://issuu.com/land-magazines/docs/l1</a></li><li class="n193"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.jot.fm/issues/issue_2007_07/column5/>http://www.jot.fm/issues/issue_2007_07/c</a></li><li class="n196"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://cloud.google.com/files/PCI_DSS_Shared_Responsibility_GCP_v32.pdf>https://cloud.google.com/files/PCI_DSS_S</a></li><li class="n197"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.dis.uniroma1.it/~labrob/pub/papers/RobAutSyst07.pdf>https://www.dis.uniroma1.it/~labrob/pub/</a></li><li class="n198"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=4609443>https://ieeexplore.ieee.org/xpl/topAcces</a></li><li class="n200"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.dis.uniroma1.it/~labrob/pub/papers/IROS05_Visual.pdf>https://www.dis.uniroma1.it/~labrob/pub/</a></li><li class="n204"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.dis.uniroma1.it/~labrob/pub/papers/IROS05_Visual.pdf>http://www.dis.uniroma1.it/~labrob/pub/p</a></li><li class="n209"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.iri.upc.edu/files/scidoc/1412-Uncalibrated-image-based-visual-servoing.pdf>http://www.iri.upc.edu/files/scidoc/1412</a></li><li class="n216"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/10-4/advanced10-4.pdf>https://www.fq.math.ca/Scanned/10-4/adva</a></li><li class="n217"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://storage.googleapis.com/science-fair/Official_Rules_Google_Science_Fair_2018.en.pdf>https://storage.googleapis.com/science-f</a></li><li class="n219"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.facebook.com/KingJongInSupport/posts/526888324568549>https://www.facebook.com/KingJongInSuppo</a></li><li class="n222"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://abc.xyz/investor/static/pdf/2016_Q4_Earnings_Transcript.pdf>https://abc.xyz/investor/static/pdf/2016</a></li><li class="n225"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/1-3/hoggatt2.pdf>https://www.fq.math.ca/Scanned/1-3/hogga</a></li><li class="n226"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://olbolui.olbenefits.ml.com/publish/content/application/pdf/GWMOL/FedFundWireTransfer_04242014.pdf>https://olbolui.olbenefits.ml.com/publis</a></li><li class="n228"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://d2mguk73h8xisw.cloudfront.net/media/filer_public/filer_public/2015/04/21/9d-letting-my-butterflies-go_1244.pdf>http://d2mguk73h8xisw.cloudfront.net/med</a></li><li class="n230"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://prod1-kl01-ecommprod04-aws-travisperkins-cloud-public.s3.amazonaws.com/sys-master/images/h43/hf1/8934627639326/KL%20Price%20Increase%20Letter%202019-2020.pdf>https://prod1-kl01-ecommprod04-aws-travi</a></li><li class="n241"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.osha.gov/SLTC/robotics/standards.html>https://www.osha.gov/SLTC/robotics/stand</a></li><li class="n244"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://searchsoftwarequality.techtarget.com/definition/software-requirements-specification>https://searchsoftwarequality.techtarget</a></li><li class="n245"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.cse.aucegypt.edu/~rafea/SATA/Reports/RequirementsSpecifications-Rafea-3.pdf>http://www.cse.aucegypt.edu/~rafea/SATA/</a></li><li class="n250"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://mathcast.sourceforge.net/MathCast_SRS_documentation.pdf>http://mathcast.sourceforge.net/MathCast</a></li><li class="n256"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6189422/>https://www.ncbi.nlm.nih.gov/pmc/article</a></li><li class="n264"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.wichita.edu/academics/engineering/openhouse/engineering_open_house_projects.php>https://www.wichita.edu/academics/engine</a></li><li class="n266"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.academia.edu/29934845/State_of_the_Art_Report_on_Video-Based_Graphics_and_Video_Visualization>https://www.academia.edu/29934845/State_</a></li><li class="n271"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.jaysonjc.com/programming/how-to-write-a-software-requirements-specification-srs-document.html>https://www.jaysonjc.com/programming/how</a></li><li class="n275"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://encyclopedia2.thefreedictionary.com/hardware+interface>https://encyclopedia2.thefreedictionary.</a></li><li class="n277"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://evothings.com/how-to-connect-your-phone-to-your-esp8266-module/>https://evothings.com/how-to-connect-you</a></li><li class="n279"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://encyclopedia2.thefreedictionary.com/Computer+interface>https://encyclopedia2.thefreedictionary.</a></li><li class="n303"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.kernel.org/doc/mirror/ols2007v1.pdf>https://www.kernel.org/doc/mirror/ols200</a></li><li class="n304"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.intersourcesoftware.com/interqa/news/>https://www.intersourcesoftware.com/inte</a></li><li class="n308"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.feeltennis.net/watching-the-ball/>https://www.feeltennis.net/watching-the-</a></li><li class="n318"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://ocw.mit.edu/courses/sloan-school-of-management/15-769-operations-strategy-spring-2003/lecture-notes/roadmapwkshp.pdf>https://ocw.mit.edu/courses/sloan-school</a></li><li class="n319"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://en.wikiversity.org/wiki/Project_Management/Work_Breakdown_Structure>https://en.wikiversity.org/wiki/Project_</a></li><li class="n320"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://osp.mans.edu.eg/elbeltagi/CPM322E%20CH1%20Planning.pdf>http://osp.mans.edu.eg/elbeltagi/CPM322E</a></li><li class="n321"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.vtt.fi/inf/pdf/science/2014/S55.pdf>https://www.vtt.fi/inf/pdf/science/2014/</a></li><li class="n322"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://dl.acm.org/citation.cfm?id=3300128>https://dl.acm.org/citation.cfm?id=33001</a></li><li class="n324"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://niryo.com/2016/12/learn-robotics-arduino/>https://niryo.com/2016/12/learn-robotics</a></li><li class="n329"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.educba.com/is-python-open-source/>https://www.educba.com/is-python-open-so</a></li><li class="n330"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.slideshare.net/jamserra/introduction-to-azure-databricks-83448539>https://www.slideshare.net/jamserra/intr</a></li><li class="n336"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.cdc.gov/std/bv/the-facts/bv-the-facts-2007.pdf>https://www.cdc.gov/std/bv/the-facts/bv-</a></li><li class="n337"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://olbolui.olbenefits.ml.com/Publish/Content/application/pdf/GWMOL/loa_checks.pdf>https://olbolui.olbenefits.ml.com/Publis</a></li><li class="n338"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.wattpad.com/762958862-%F0%9D%90%83%F0%9D%90%80%F0%9D%90%93%F0%9D%90%88%F0%9D%90%8D%F0%9D%90%86-%F0%9D%90%86%F0%9D%90%80%F0%9D%90%8C%F0%9D%90%84%F0%9D%90%92-%E2%9C%93-5-r-e-s-u-l-t-s>https://www.wattpad.com/762958862-%F0%9D</a></li><li class="n339"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://issuu.com/wengercorp/docs/2013-2014_music_education>https://issuu.com/wengercorp/docs/2013-2</a></li><li class="n343"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.federalreserve.gov/pubs/feds/1996/199644/199644pap.pdf>https://www.federalreserve.gov/pubs/feds</a></li><li class="n353"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://kb.informatica.com/h2l/HowTo%20Library/1/0956-Configuring_SFTP_Connections_in_PowerCenter-H2L.pdf>https://kb.informatica.com/h2l/HowTo%20L</a></li><li class="n354"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://link.springer.com/article/10.1007/s11042-017-4454-y>https://link.springer.com/article/10.100</a></li><li class="n355"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.slideshare.net/SmritiTikoo/detection-and-recognition-of-face-using-neural-network>https://www.slideshare.net/SmritiTikoo/d</a></li><li class="n356"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://tryolabs.com/resources/introductory-guide-computer-vision/>https://tryolabs.com/resources/introduct</a></li><li class="n357"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fidelity.com/bin-public/060_www_fidelity_com/documents/barrons-reprint.pdf>https://www.fidelity.com/bin-public/060_</a></li><li class="n358"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.slideshare.net/SmritiTikoo/face-detection-62383927>https://www.slideshare.net/SmritiTikoo/f</a></li><li class="n361"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://ijesrt.com/issues%20pdf%20file/Archive-2018/April-2018/80.pdf>http://ijesrt.com/issues%20pdf%20file/Ar</a></li><li class="n364"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.academia.edu/10134514/MOBILE_BANKING_USING_ANDROID_BASED_BIOMETRICS_SYSTEM>https://www.academia.edu/10134514/MOBILE</a></li><li class="n366"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.ijser.org/paper/Design-of-Human-Facial-Feature-Recognition-System.html>https://www.ijser.org/paper/Design-of-Hu</a></li><li class="n367"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.ijesrt.com/issues%20pdf%20file/Archive-2017/July-2017/31.pdf>http://www.ijesrt.com/issues%20pdf%20fil</a></li><li class="n369"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.analyticsinsight.net/manual-to-object-detection-with-machine-learning/>https://www.analyticsinsight.net/manual-</a></li><li class="n374"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://openaccess.thecvf.com/content_cvpr_2017_workshops/w10/papers/Wong_Uncertainty_Quantification_of_CVPR_2017_paper.pdf>http://openaccess.thecvf.com/content_cvp</a></li><li class="n375"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://arxiv.org/pdf/1806.04548>https://arxiv.org/pdf/1806.04548</a></li><li class="n376"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ACCV_2014/pages/workshop14/pdffiles/w14-p1.pdf>http://vigir.missouri.edu/~gdesouza/Rese</a></li><li class="n379"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://americanenglish.state.gov/files/ae/resource_files/tom-sawyer-mark-twain_0.pdf>https://americanenglish.state.gov/files/</a></li><li class="n383"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://ec.europa.eu/europeaid/sites/devco/files/evaluation-methods-guidance-vol4_en.pdf>https://ec.europa.eu/europeaid/sites/dev</a></li><li class="n385"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2553854/>https://www.ncbi.nlm.nih.gov/pmc/article</a></li><li class="n386"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.kenaston.org/the-pitch/law-02.htm>http://www.kenaston.org/the-pitch/law-02</a></li><li class="n390"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://quizlet.com/65361679/suspension-steering-practice-test-4-flash-cards/>https://quizlet.com/65361679/suspension-</a></li><li class="n398"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.oecd.org/chemicalsafety/risk-assessment/1948257.pdf>http://www.oecd.org/chemicalsafety/risk-</a></li><li class="n401"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.nikon.co.in/en_IN/product/digital-slr-cameras/d850>http://www.nikon.co.in/en_IN/product/dig</a></li><li class="n405"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://link.springer.com/article/10.1007%2Fs11263-019-01247-4>https://link.springer.com/article/10.100</a></li><li class="n406"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.bbc.com/earth/story/20160324-how-our-deadliest-disease-infected-us>http://www.bbc.com/earth/story/20160324-</a></li><li class="n408"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.weareworldquant.com/en/thought-leadership/understanding-images-computer-vision-in-flux/>https://www.weareworldquant.com/en/thoug</a></li><li class="n409"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://en.wikisource.org/wiki/The_Grammar_of_English_Grammars/Part_III>https://en.wikisource.org/wiki/The_Gramm</a></li><li class="n412"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://uwosh.edu/registrar/wp-content/uploads/sites/117/2019/04/ADD_DROP-CARD-WEBSITE-updated-4_25_19.pdf>https://uwosh.edu/registrar/wp-content/u</a></li><li class="n415"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://smartfile.s3.amazonaws.com/171c8a78170f0512f8240c082e87317b/uploads/2019/10/Year-8-Creativity-Day-Letter-Portsmouth-and-the-Mary-Rose.pdf>https://smartfile.s3.amazonaws.com/171c8</a></li><li class="n416"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://s3-eu-west-1.amazonaws.com/websites-wordpress-uploads/white-swan.co.uk/wp-content/uploads/2019/05/Breakfast-Menu-1.pdf>https://s3-eu-west-1.amazonaws.com/websi</a></li><li class="n419"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/28-3/elementary28-3.pdf>https://www.fq.math.ca/Scanned/28-3/elem</a></li><li class="n425"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.linkedin.com/in/engineer-jeff-pakingan>https://www.linkedin.com/in/engineer-jef</a></li><li class="n426"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.eeai.net/uploads/1/7/6/4/17642065/eeai_rd_job_description_2019__2_.pdf>https://www.eeai.net/uploads/1/7/6/4/176</a></li><li class="n430"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://issuu.com/uhengineering/docs/parameters_fall_2019_online_large>https://issuu.com/uhengineering/docs/par</a></li><li class="n432"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.intechopen.com/books/operations-management/improving-operations-performance-with-world-class-manufacturing-technique-a-case-in-automotive-indus>https://www.intechopen.com/books/operati</a></li><li class="n433"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://history.cap.gov/file/151>http://history.cap.gov/file/151</a></li><li class="n437"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://campussuite-storage.s3.amazonaws.com/prod/1558545/607ba008-3c23-11e8-a30f-12ec69a7c3ac/1810621/cddd15c8-9bfa-11e8-98f9-12e259a87d5e/file/ADA%20Final%20CLTCC%20Alexandria%20-Press%20Conference%20Presentation.pdf>https://campussuite-storage.s3.amazonaws</a></li><li class="n438"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://id.123dok.com/document/zkx5dl4y-cbap-certification-and-babok-study-guide-pdf-pdf.html>https://id.123dok.com/document/zkx5dl4y-</a></li><li class="n439"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.proofhub.com/articles/project-management-challenges>https://www.proofhub.com/articles/projec</a></li><li class="n440"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.mdpi.com/2073-8994/11/12>https://www.mdpi.com/2073-8994/11/12</a></li><li class="n441"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://kids.kiddle.co/Computer_vision>https://kids.kiddle.co/Computer_vision</a></li><li class="n442"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://software.intel.com/en-us/articles/implement-hand-gesture-recognition-with-xrdrive-sim>https://software.intel.com/en-us/article</a></li><li class="n443"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://digitaleyeshs.blogspot.com/2011/02/computer-vision-and-human-vision.html>https://digitaleyeshs.blogspot.com/2011/</a></li><li class="n444"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://blog.acolyer.org/2016/11/21/artificial-intelligence-and-life-in-2030/>https://blog.acolyer.org/2016/11/21/arti</a></li><li class="n445"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://allcybernetics.blogspot.com/2009/01/computer-vision.html>https://allcybernetics.blogspot.com/2009</a></li><li class="n446"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://amedleyofpotpourri.blogspot.com/2018/06/computer-vision.html>https://amedleyofpotpourri.blogspot.com/</a></li><li class="n447"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://amedleyofpotpourri.blogspot.com/2019/04/computer-vision.html>https://amedleyofpotpourri.blogspot.com/</a></li><li class="n451"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.ncbi.nlm.nih.gov/labs/journals/cell-mol-neurobiol/>https://www.ncbi.nlm.nih.gov/labs/journa</a></li><li class="n452"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://ranahammad.blogspot.com/2006/03/>https://ranahammad.blogspot.com/2006/03/</a></li><li class="n455"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://scholarlykitchen.sspnet.org/2017/03/10/different-levels-complexity-require-different-communication-strategies/>https://scholarlykitchen.sspnet.org/2017</a></li><li class="n457"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://link.springer.com/chapter/10.1007%2F11790853_35>https://link.springer.com/chapter/10.100</a></li><li class="n458"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://wikimili.com/en/Computer_vision>https://wikimili.com/en/Computer_vision</a></li><li class="n461"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.slideshare.net/rolando718/image-processing-4345975>https://www.slideshare.net/rolando718/im</a></li><li class="n466"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.slideshare.net/shivakrishnashekar/computer-vision-25544257>https://www.slideshare.net/shivakrishnas</a></li><li class="n468"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.idc-online.com/technical_references/pdfs/electronic_engineering/Computer_Vision.pdf>http://www.idc-online.com/technical_refe</a></li><li class="n473"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://arkvianen.nl/images/pdf/Sintlogboek_2019.pdf>https://arkvianen.nl/images/pdf/Sintlogb</a></li><li class="n476"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://nebula.wsimg.com/6e4c7ea24af38582f2acbf0f40eef502?AccessKeyId=CA84610571F52D295FEA&disposition=0&alloworigin=1>http://nebula.wsimg.com/6e4c7ea24af38582</a></li><li class="n480"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px>1%</span> <a class="show_texts" href=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.3430>http://citeseerx.ist.psu.edu/viewdoc/sum</a></li><li class="n485"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.courzyvite.fr/18Resultats/10kmMoirans2018.pdf>https://www.courzyvite.fr/18Resultats/10</a></li><li class="n490"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.fq.math.ca/Scanned/6-4/advanced6-4.pdf>https://www.fq.math.ca/Scanned/6-4/advan</a></li><li class="n503"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://www.skillsyouneed.com/ips/group-roles.html>https://www.skillsyouneed.com/ips/group-</a></li><li class="n504"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.umsl.edu/~sauter/analysis/6840_f03_papers/zhou/>http://www.umsl.edu/~sauter/analysis/684</a></li><li class="n505"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.cs.ox.ac.uk/teaching/courses/projects/>http://www.cs.ox.ac.uk/teaching/courses/</a></li><li class="n513"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://bib.irb.hr/datoteka/251411.CALLDL_Seljan.pdf>https://bib.irb.hr/datoteka/251411.CALLD</a></li><li class="n536"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://dictionary.sensagent.com/holovid/en-en/>http://dictionary.sensagent.com/holovid/</a></li><li class="n537"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=http://www.k2.t.u-tokyo.ac.jp/fusion/index-e-past.html>http://www.k2.t.u-tokyo.ac.jp/fusion/ind</a></li><li class="n538"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://martinperis.blogspot.com/2011/01/visual-servoing-with-mrds-and-emgucv.html>https://martinperis.blogspot.com/2011/01</a></li><li class="n539"><span style=color:#ffffff;background-color:#95a5a6;text-align:center;position:relative;display:inline-block;width:35px><1%</span> <a class="show_texts" href=https://visp-doc.inria.fr/doxygen/visp-daily/citelist.html>https://visp-doc.inria.fr/doxygen/visp-d</a></li>
<li class="class#"> <a class="show_texts" href="#"></a> </li>
<!--Links_End-->

<!--Footer_Start-->
</ul>
<a href="#" title="Click on the link to see all sources" class="all_sources">View all sources</a> </div>
<div class="clear">&nbsp;</div>
</div>
</div>
</div>
</div>
</div>
<script type="text/javascript">
$('.show_texts').attr("title",'Click on the link to visit the source.');

$('.red_selection, .green_selection').live('click', function () {
unselect_selection();
var link_class = $(this).attr('id');
$(this).removeClass('red_selection').addClass('green_selection');
$('.list_link li').hide();
$('.list_link li.' + link_class).show();
$('.sources_hint').text('Click on the link below to visit the source.');
$('.all_sources').show();
checkListHeader();
});

//Show Sources
$('a.plag_sources, a.all_sources').click(function () {
unselect_selection();
$('.list_link li').show();
$('.sources_hint').text('Click on the link below to visit the source.');
$('.all_sources').hide();
checkListHeader();
return false;
});


//Exuecute Sources
$('.list_link li a.show_texts').click(function () {
unselect_selection();
var classList = $(this).parent().attr('class').split(/\s+/);
var url=$(this).attr('href');
if(url!='Empty'){ window.open(url, '_blank'); }
return false;
});

function unselect_selection() {
$('.green_selection').removeClass('green_selection').addClass('red_selection');
}

function checkListHeader() {
$('.list_link').each(function () {
if ($(this).find('li:visible').length) {
$(this).find('h3').show();
} else {
$(this).find('h3').hide();
}
})
}

$(function () {
$.jatt();

//Reset Selection & Show Links
unselect_selection();
$('.all_sources').hide();
$('.list_link li').show();
checkListHeader();

});

</script>
</div>
</body>
</html>
<!--Footer_End-->

